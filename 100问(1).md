1. HDFS的架构	

2. HDFS的读写流程	

3. Secondary NameNode 了解吗，它的工作机制是怎样的	

4. join原理	

5. yarn 的任务提交流程是怎样的	

6. zookeeper集群的节点数为什么建议奇数台	

7. Zab协议	

8. 简述kafka的架构	

9. kafka是如何保证数据不丢失和数据不重复	

10. kafka中的数据是有序的吗，如何保证有序的呢	

11. kafka的数据是放在磁盘上还是内存上，为什么速度会快	

12. HBase 中 compact 用途是什么，什么时候触发，分为哪两种，有什么区别	

13. 说一下HBase 的 rowkey 设计原则	

14. hive的join底层实现	

15. Order By和Sort By的区别	

16. 自定义过UDF、UDTF函数吗	

17. Hive优化	

18. 简述hadoop 和 spark 的不同点（为什么spark更快）	

19. 你知道Application、Job、Stage、Task他们之间的关系吗		

20. 宽依赖和窄依赖之间的区别	

21. sparksql的三种join实现		

22. 简述SparkStreaming窗口函数的原理	

23. 简单介绍一下Flink	

24. Flink和SparkStreaming区别		

25. java中==和equals的区别	

26. HashMap底层实现	

27. HashMap扩容过程	

28. 异常体系	

29. JVM一个类的加载过程	

30. JVM中的垃圾回收算法	

31. JVM垃圾收集器 	

32. java实现多线程有几种方式	

33. 线程池相关内容	

34. synchronized 的原理	

35. TCP连接管理	

36. TCP和UDP的区别	

37. 浏览器输入URL到显示页面的过程	

38. 进程和线程的区别	

39. 什么是死锁以及死锁的四个条件	

40. 简述事务	

41. 数据库事务并发会引发哪些问题	

42. MVCC讲一下（怎么实现）	

43. 为什么要对数据仓库分层	

44. 数据仓库建模的方法有哪些	

45. 事实表的设计过程	

46. 留存问题	

47. 数据倾斜	


-------------------------
--携程
1. HDFS的写入流程？如果一台机器宕机，HDFS怎么保证数据的一致性？如果只存活一台机器又会发生什么情况？

2. NameNode HA的实现原理？如何避免NameNode脑裂的情况？

   > "脑裂"是在分布式系统中一个常见的问题，特别是在主备（master/standby）架构中，这种现象可能会发生。当两个或多个节点都认为自己是主节点时，就会发生"脑裂"现象。这可能会导致数据不一致或数据丢失。
   >
   > 在Hadoop HDFS中，NameNode是一个关键组件，它负责管理文件系统的元数据，同时也是客户端访问文件的入口点。在早期的Hadoop版本中，NameNode是单点故障（Single Point of Failure），如果它崩溃了，整个HDFS就会不可用。为了解决这个问题，后续的Hadoop版本引入了主备（Active/Standby）NameNode配置。
   >
   > 为了避免NameNode的"脑裂"现象，Hadoop 2.0 引入了ZooKeeper用于选举和故障切换。在主备架构中，只有一个NameNode处于活动状态，另一个处于备用状态。使用ZooKeeper来管理哪个节点应该是活动的，以及当活动节点故障时进行故障切换。
   >
   > ZooKeeper是一个开源的，用于维护配置信息，命名，提供分布式同步，组服务等的分布式应用程序协调服务。它提供了一种高效且可靠的分布式锁服务，这正是我们用来解决"脑裂"问题所需的。
   >
   > 如果主NameNode出现故障，ZooKeeper将检测到这一点并开始选举新的主NameNode，然后备用NameNode就会接管，并从编辑日志中加载最新的文件系统元数据状态。这个过程对客户端来说是透明的，虽然在故障切换期间，客户端的请求可能会被暂时阻塞。
   >
   > 所以，使用ZooKeeper进行主节点选举和故障转移，可以避免Hadoop HDFS中NameNode的"脑裂"现象。

3. 如果数据量比较大，如何解决NameNode 的内存瓶颈？

4. MapReduce Shuffle中Reduce是怎么获得Map输出的分区文件，Map主动推还是Reduce主动拉？

   > 在 MapReduce 模型中，Map 阶段的输出在 Reduce 阶段前需要经历 Shuffle 和 Sort 过程。这个过程涉及到数据在 Map 端和 Reduce 端之间的移动。
   >
   > 在 Shuffle 过程中，是 Reduce 任务主动拉取 Map 任务输出的数据。
   >
   > 具体过程如下：
   >
   > 1. Map 任务执行完毕后，会将结果按照 Reduce 任务的数量分区，并将各个分区的数据写到本地磁盘。
   > 2. 每个 Reduce 任务会从 JobTracker（或 YARN 中的 ApplicationMaster）获取它需要处理的 Map 任务列表。
   > 3. Reduce 任务根据得到的 Map 任务列表，对每一个 Map 任务，通过 HTTP 方式从 Map 任务所在节点的本地磁盘拉取对应的分区数据。
   > 4. Reduce 任务获取到数据后，会对数据进行排序（Sort）并执行 Reduce 操作。
   >
   > 这样设计的原因是，一般来说 Map 任务的数量比 Reduce 任务的数量要多得多，如果使用 Map 任务主动推的方式，会造成 Reduce 任务端的网络接口和 IO 成为瓶颈。反之，如果使用 Reduce 任务主动拉取的方式，可以更好地利用网络带宽，避免在 Reduce 任务端形成网络和 IO 瓶颈。

5. Kafka如何实现顺序消费？

6. Spark Streaming消费Kafka的两种方式比较。如何提高Spark Streaming消费Kafka的并行度？

7. 如何保证Spark Streaming的精准一次性消费？

8. 项目中Spark Streaming消费Kakfa的offset保存在哪里？为什么不采用checkpoint保存offset，有什么缺点？

9. 对Spark RDD的理解。

10. Spark作业运行流程？（从standalone和yarn两种模式进行阐述）

11. 项目中Spark采用的那种模式搭建的？为什么采用standalone而不采用yarn模式？

12. 为什么Spark Shuffle比MapReduce Shuffle快（至少说出4个理由）？

13. Spark3新特性

14. Java中保证线程安全的方法有哪些？

15. 一个volatile修饰的变量，如果两个线程同时去写这个变量，线程安全吗？如果不安全该怎么使他变得安全？

16. Linux中怎么查看一个进程打开了哪些文件？

17. 算法题：二叉树非递归中序遍历

------------------------------
#### 答案（对应问题序号）：

1. HDFS的架构

   1. https://blog.csdn.net/solihawk/article/details/123981573
        1.1解释下FsImage和Edits的作用，他们是怎么工作的？

     > Hadoop Distributed File System（HDFS）是一种分布式文件系统，用于存储大量数据并在集群上进行分布式处理。FsImage和Edits是HDFS的两个重要组件，它们都是元数据存储的核心。
     >
     > 1. FsImage：FsImage（文件系统映像）是HDFS NameNode的持久化元数据存储。FsImage包含了HDFS集群中所有文件和目录的信息，例如权限、所有者、副本数等。FsImage文件是一个序列化的镜像，包含了NameNode内存中文件系统的全局快照。FsImage在NameNode启动时加载到内存，以便在运行时迅速响应客户端请求。
     >
     > 2. Edits：Edits（编辑日志）是HDFS中用于记录文件系统更改的日志文件。NameNode在内存中维护文件系统的状态，当客户端对文件系统进行操作（如创建、删除或重命名文件/目录）时，NameNode会将这些操作记录到Edits日志中。Edits日志是增量式的，只记录自上次FsImage创建以来发生的更改。
     >
     > FsImage和Edits的工作原理：
     >
     > 1. 当NameNode启动时，它首先从FsImage文件加载文件系统元数据到内存。
     > 2. 随后，NameNode会从Edits日志中回放所有记录的更改，以便将内存中的文件系统状态更新到最新。
     > 3. 在NameNode运行期间，所有对文件系统的更改都会记录在Edits日志中。
     > 4. 为了防止Edits日志过大，NameNode会定期执行一次检查点操作（checkpoint），这个过程包括将FsImage和Edits日志合并，并创建一个新的FsImage文件。新的FsImage包含了所有最近的文件系统更改，而Edits日志会被清空或截断，从而避免了Edits日志无限制增长。
     >
     > 总的来说，FsImage和Edits在HDFS中扮演着至关重要的角色，它们一起维护了HDFS文件系统的元数据，并确保了NameNode在故障恢复后能够正确恢复文件系统状态。

2. HDFS的读写流程	

3. Secondary NameNode 了解吗，它的工作机制是怎样的	

4. join原理	

5. yarn 的任务提交流程是怎样的	

6. zookeeper集群的节点数为什么建议奇数台	

7. Zab协议	

8. 简述kafka的架构	

9. kafka是如何保证数据不丢失和数据不重复	

10. kafka中的数据是有序的吗，如何保证有序的呢	

11. kafka的数据是放在磁盘上还是内存上，为什么速度会快	

12. HBase 中 compact 用途是什么，什么时候触发，分为哪两种，有什么区别	

13. 说一下HBase 的 rowkey 设计原则	

14. hive的join底层实现	

15. Order By和Sort By的区别	

16. 自定义过UDF、UDTF函数吗	

17. Hive优化	

18. 简述hadoop 和 spark 的不同点（为什么spark更快）	

19. 你知道Application、Job、Stage、Task他们之间的关系吗		

20. 宽依赖和窄依赖之间的区别	

21. sparksql的三种join实现		

22. 简述SparkStreaming窗口函数的原理	

23. 简单介绍一下Flink	

24. Flink和SparkStreaming区别		

25. java中==和equals的区别	

26. HashMap底层实现	

27. HashMap扩容过程	

28. 异常体系	

29. JVM一个类的加载过程	

30. JVM中的垃圾回收算法	

31. JVM垃圾收集器 	

32. java实现多线程有几种方式	

33. 线程池相关内容	

34. synchronized 的原理	

35. TCP连接管理	

36. TCP和UDP的区别	

37. 浏览器输入URL到显示页面的过程	

38. 进程和线程的区别	

39. 什么是死锁以及死锁的四个条件	

40. 简述事务	

41. 数据库事务并发会引发哪些问题	

42. MVCC讲一下（怎么实现）	

43. 为什么要对数据仓库分层

    > 1. 性能和效率：通过将数据仓库分层，可以将数据按照用途和访问频率进行分组。这样，频繁访问的数据可以存储在高速访问的层级中，而不常访问的数据可以存储在低速访问的层级中。这样可以提高数据的检索速度，提高系统的性能和效率。
    > 2. 数据安全性：某些层级的数据可能需要更严格的安全控制，例如包含敏感信息的数据。分层可以更好地管理这些数据的安全性。
    > 3. 数据质量和完整性：分层还有助于保持数据的质量和完整性。在分层结构中，可以为不同的层级设置不同的数据质量和完整性规则。
    > 4. 方便管理：通过将数据分层，可以更方便地进行数据管理。例如，可以根据需要对不同的层级进行备份和恢复。
    > 5. 提供更好的数据理解：分层的数据仓库可以帮助用户更好地理解数据结构和数据的关系，从而更有效地使用数据。
    > 6. 提高数据处理的灵活性：数据分层为实现多种不同的数据查询和分析需求提供了便利，可以灵活地处理各层级的数据以满足不同的业务需求。例如，对于复杂的分析需求，可以使用存储在底层的详细数据；对于一般的报告需求，可以使用存储在上层的汇总数据。
    >
    > ​	

44. 数据仓库建模的方法有哪些	

    https://blog.csdn.net/qq_26442553/article/details/105506364

45. 事实表的设计过程	

46. 留存问题	

47. 数据倾斜	



