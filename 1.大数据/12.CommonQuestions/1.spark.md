https://zhuanlan.zhihu.com/p/440179932

1. **介绍下Spark**

2. **谈一谈Spark的生态体系**

3. **Spark的任务执行流程**  

   总体示意图：

   ![](https://springboot-vue-blog.oss-cn-hangzhou.aliyuncs.com/img-for-typora/Spark%E4%BB%BB%E5%8A%A1%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png)

   可以结合运行模式及原理细说

   * 客户端提交任务，创建**Driver进程**并初始化SparkContext，SparkContext对象代表了和一个集群的连接
   * SparkContext向Cluster Manager（资源管理器）申请资源
   * Cluster Manager 选择合适的worker节点**（一个或多个）**创建**executor进程**
   * executor向driver端注册，并等待其分配任务
   * SparkContext根据RDDs之间的依赖关系构建DAG图（有向无环图），**DAGScheduler将DAG图解析成Stage**，每个Stage有多个task，形成taskset发送给task Scheduler，由task Scheduler将Task发送给Executor运行
   * Executor启动Task线程执行具体任务，运行完释放所有资源

4. **Spark运行模式有哪些？说说你最熟悉的一种**

   Spark的运行模式包括**Local、Standalone、Yarn及Mesos**几种。其中Local模式仅用于本地开发，Mesos模式国内几乎不用。在公司中因为大数据服务基本搭载Yarn集群调度，因此Spark On Yarn模式会用的比较多。

   Standalone模式是**Spark内置的运行模式**，常用于小型测试集群。这里就拿Standalone模式来举例:

   - Master为资源调度器，负责executors资源调度
   - Worker负责Executor进程的启动和监控
   - **Driver在客户端启动**，负责SparkContext初始化

   ![](https://springboot-vue-blog.oss-cn-hangzhou.aliyuncs.com/img-for-typora/Spark%E7%9A%84Standalone%E6%A8%A1%E5%BC%8F.png)

4. **Yarn Cluster和Yarn Client模式的区别**

   * 在Yarn模式中，Spark应用程序有两种运行模式：
     		**yarn-client**：Driver程序运行在**本地客户端**，适用于交互、调试，希望立即看到app的输出。因资源调度、任务分发会和yarn集群产生大量网络通信，不建议生产上使用。
       		**yarn-cluster**：Driver程序运行在由RM启动的 AppMaster中，适用于生产环境
     二者的主要区别：Driver在哪里。

   * Yarn Cluster模式

     ![img](https://springboot-vue-blog.oss-cn-hangzhou.aliyuncs.com/img-for-typora/v2-b9239e2e387f9ba7d3b4d2c30b14f307_1440w.jpg)

   * Yarn Client模式
   
     ![img](https://springboot-vue-blog.oss-cn-hangzhou.aliyuncs.com/img-for-typora/v2-36da1a71b1d1c36cde73465504c2f2a5_1440w.jpg)
   
6. 为什么Spark Shuffle比MapReduce Shuffle快（至少说出4个理由）？

   > 1. Spark 计算比 MapReduce 快的根本原因在于 **DAG 计算模型**。一般而言，DAG 相比MapReduce 在大多数情况下可以减少 shuffle 次数。
   >
   > 2. 数据结构和算法优化：
   >
   >    1）Spark Shuffle的排序和分组操作，采用了**Tungsten内存管理**和**二进制编码**技术，可以**将数据序列化为紧凑的二进制格式**，并使用专门的编码和解码器来**避免Java对象序列化和反序列化的开销**，从而提高数据的传输和处理速度。从而显著提高性能和可扩展性。
   >
   >    2）MapReduce框架本身并不支持直接生成二进制代码。**在MapReduce中，数据通常是序列化为文本格式**，例如JSON、XML、CSV等。在MapReduce Shuffle阶段中，数据通常是通过网络传输和磁盘存储，使用**Java序列化技术将数据序列化为字节数组**，再在Reduce端进行反序列化和处理。
   >
   >    注：虽然MapReduce框架本身不支持直接生成二进制代码，但是可以使用其他工具和库来实现。例如，可以使用Avro、Thrift、Protocol Buffers等二进制数据序列化和反序列化框架，将数据序列化为紧凑的二进制格式。
   >
   > 2. MapReduce的设计：中间结果**保存在磁盘**中，提高了可靠性，但是减少了内存占用，牺牲了性能。
   >
   >    1）**map task必须将所有的数据都写入本地磁盘文件以后，才能启动reduce操作，来拉取数据。**为什么？因为mapreduce要实现默认的根据key的排序！所以要排序，肯定得写完所有数据，才能排序，然后reduce来拉取。
   >
   >    2）但是Spark不需要，spark默认情况下，是不会对数据进行排序的。因此ShuffleMapTask每写入一点数据，ResultTask就可以拉取一点数据，然后在本地执行我们定义的聚合函数和算子，进行计算。
   >
   >    Spark的设计：数据在**内存中进行交换**，要快一些，降低了可靠性，但是提升了性能。
   >
   >    1）如果计算不涉及与其他节点进行数据交换，Spark 可以在内存中一次性完成这些操作，也就是中间结果无须落盘，减少了磁盘 IO 的操作。
   >
   >    2）注：如果计算过程中涉及数据交换，Spark 也是会把 shuffle 的数据写磁盘的！
   >
   > 1. MapReduce是细粒度资源申请，当提交application的时候，task执行时，通过心跳通信，**自己申请资源，自己释放资源**，task执行完毕之后，资源立即会被释放，**task执行的慢。**
   >
   >    而spark是粗粒度资源申请，也就是当提交spark application的时候，application会将所有的资源申请完毕，如果申请不到资源就等待，如果申请到资源才执行application。那么task在执行的时候就**不需要自己去申请资源**，**task执行快**，当最后一个task执行完之后task才会被释放。
   
7. Spark Streaming消费Kafka的两种方式比较？

   > 在Direct方式中，Spark Streaming直接从Kafka中读取数据并行处理，这种方式具有更低的延迟和更高的可靠性，因为它使用了Kafka的高级别消费者API，并在Kafka和Spark之间建立了一个一对一的连接。
   >
   > 而在Receiver-based方式中，Spark Streaming通过Kafka的低级别消费者API将数据接收到一个Spark中间缓存区中，然后对数据进行处理。这种方式的缺点是存在数据的复制和不必要的存储，导致了较高的延迟和较低的可靠性。

   https://blog.csdn.net/dudadudadd/article/details/114402955

8. 如何提高Spark Streaming消费Kafka的并行度？

   > 要提高Spark Streaming消费Kafka的并行度，可以采取以下措施：
   >
   > 1. 增加Spark Streaming中的并行度参数：可以通过增加spark.streaming.kafka.maxRatePerPartition【**Kafka分区的最大处理速率（记录数/秒）参数**】或【spark.streaming.concurrentJobs**作业并行度参数**】来增加并行度，以处理更多的数据。
   > 2. 手动增加Rdd分区数、Kafka分区数：可以通过**增加Kafka中主题的分区数**、**手动增加Rdd的分区数量**，同时确保**Kafka主题的分区数与Spark Streaming的处理程序的并行度匹配**。这样，每个分区都可以并行消费，提高处理速度。
   > 3. 将数据均匀分布在分区中：确保Kafka主题的分区均匀地分布数据，并使用Kafka的分区器，以确保数据在各个分区之间均匀分布，以提高消费者的并行度。
   > 4. 配置适当的消费者组：在Direct方式中，可以使用适当的消费者组来提高并行度。消费者组允许多个消费者同时处理来自同一个Kafka主题的不同分区的数据。
   > 5. 优化Spark Streaming中的处理逻辑：可以对Spark Streaming中的数据处理逻辑进行优化，例如使用窗口操作和缓存操作来减少计算量和提高性能。
   >
   > 综上所述，要提高Spark Streaming消费Kafka的并行度，需要结合适当的调整Spark Streaming和Kafka的配置参数、优化数据分区和处理逻辑等多方面因素。