1. **HDFS文件写入和读取流程**  （☆☆☆☆☆）

   * **HDFS写数据过程**

     ![image-20220824172938620](https://springboot-vue-blog.oss-cn-hangzhou.aliyuncs.com/img-for-typora/image-20220824172938620.png)

   1）客户端通过分布式文件系统Distributed FileSystem模块向nameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。

   2）nameNode返回是否可以上传。

   3）客户端请求第一个block上传到哪几个datanode服务器上。

   4）NameNode返回3个datanode节点，分别为dn1、dn2、dn3。

   5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。

   6）dn1、dn2、dn3逐级应答客户端。

   7）客户端开始往dn1上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，dn1收到一个packet就会传给dn2，dn2传给dn3；dn1每传一个packet，会进入一个应答队列等待应答。

   8）当一个block传输完成之后，客户端再次请求NameNode上传第二个block到服务器。（重复执行3~7步）

   * **HDFS读数据流程**

     ![image-20220824172950541](https://springboot-vue-blog.oss-cn-hangzhou.aliyuncs.com/img-for-typora/image-20220824172950541.png)

   1）客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件快所在的DataNode地址。

   2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。

   3）dataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以packet为单位来做校验）。

   4）客户端以packet为单位接收，先在本地缓存，然后写入目标文件。

2. **HDFS组成架构** （☆☆☆☆☆）

   ![image-20220824172912456](https://springboot-vue-blog.oss-cn-hangzhou.aliyuncs.com/img-for-typora/image-20220824172912456.png)

   架构主要由四部分组成：**HDFS Client、NameNode、DataNode和Secondary NameNode**

   1）HDFS Client：客户端

   1. 文件切分。文件上传HDFS的时候，Client将文件切分成一个个的block，然后进行存储；
   2. 与nameNode交互，获取文件的位置信息；
   3. 与dataNode交互，读取或者写入数据；
   4. Client提供一些命令来管理HDFS,比如启动或者关闭HDFS
   5. Client可以通过一些命令来访问HDFS；

   2）nameNode：就是master，他是一个主管、管理者。

   1. 管理HDFS的名称空间；
   2. 管理数据块（Block）映射信息；
   3. 配置副本策略；
   4. 处理客户端读写请求。

   3）DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。

   1. 存储实际的数据块；
   2. 执行数据块的读/写操作。

   4）Secondary NameNode：**并非**NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。

   1. 辅助nameNode，分担其工作量
   2. 定期合并Fsimage和Edits，并推送给NameNode
   3. 在紧急情况下，可辅助恢复NameNode。

3. **介绍下HDFS，说下HDFS优缺点，以及使用场景**  

4. **HDFS作用** 

5. **HDFS的容错机制**  

   文件系统的容错可以通过**NameNode高可用、SecondaryNameNode机制、数据块副本机制和心跳机制**来实现

   ~~~
   注意：当以本地模式或者伪集群模式部署 Hadoop 时，会存在 SeconddayNameNode；当以集群模式部署 Hadoop 时，如果配置了 NameNode 的 HA 机制，则不会存在 SecondaryNameNode，此时会存在备 NameNode。
   ~~~

   **读容错**和**写容错**机制的流程如下：

   1）备用nameNode实时备份主NameNode上的元数据信息，一旦主NameNode发生故障不可用，则备 NameNode 迅速接管主 NameNode 的工作。

   2）客户端向 DataNode 读取/写入 数据，此时会分为读取数据和写入数据两种情况。

   1. **读取数据**：HDFS会检测文件快的完整性，确认文件块的**检验和**与DataNode中是否一致，如果不一致，则从其他的 DataNode 上获取相应的副本。
   2. **写入数据**：HDFS 会检测文件块的完整性，**最后一个DataNode负责**确认**校验和**与客户端发送的校验和是否一致，同时记录新创建的**文件的所有文件块的校验和**。

   3）DataNode会定期向NameNode发送心跳信息，将自身节点的状态告知NameNode；NameNode会将DataNode 需要执行的命令放入心跳信息的返回结果中，返回给 DataNode 执行。

   ​	   当 DataNode 发生故障没有正常发送心跳信息时，NameNode 会检测文件块的副本数是否小于 系统设置值，如果小于设置值，则自动复制新的副本并分发到其他的 DataNode 上。

   4）集群中有数据关联的 DataNode 之间复制数据副本。

   ​		当集群中的 DataNode 发生故障而失效，或者在集群中添加新的 DataNode 时，可能会导致数据分布**不均匀**。当某个 DataNode 上的空闲空间资源大于系统设置的临界值时，HDFS 就会从 其他的 DataNode 上将数据迁移过来。相对地，如果某个 DataNode 上的资源出现超负荷运载，HDFS 就会根据一定的规则寻找有空闲资源的 DataNode，将数据迁移过去。

   ​	还有一种从侧面说明 HDFS 支持容错的机制，即当从 HDFS 中删除数据时，数据并不是马上就会从 HDFS 中被删除，而是会将这些数据放到“回收站”目录中，随时可以恢复，直到超过了一定的时间才会真正删除这些数据。

6. **HDFS的存储机制**  

   1）[HDFS](https://so.csdn.net/so/search?q=HDFS&spm=1001.2101.3001.7020)设计出一套文件存储方式，即对文件分割后分别存放；

   2）Block（块）是HDFS的基本存储单元，默认大小是64M；

   3）**NameNode存储HDFS文件元数据，DataNode存储实际数据**；

   4）通过副本机制对已经存储的Block进行备份，这样可以快速恢复损坏的数据；

7. **HDFS的副本机制** 

       HDFS 会将数据文件切分成一个个小的数据块进行存储，同时会将这些数据块的副本保存多份，分别保存到不同的 DataNode 上。HDFS 中数据块的副本数由 hdfs-site.xml文件中的dfs.replication属性决定。
       Hadoop 默认的副本数为3，并且在机架的存放上也有一定的策略。Hadoop 的默认布局策略，即默认的副本存放策略如下：
   
          （1）第 1 个副本存放在 HDFS 客户端所在的节点上。
       
          （2）第 2 个副本存放在与第1个副本不同的机架上，并且是随机选择的节点。
          
          （3）第 3 个副本存放在与第2个副本相同的机架上，并且是不同的节点。


8. **HDFS的常见数据格式，列式存储格式和行存储格式异同点，列式存储优点有哪些?**  

   解答见HDFS目录。

9. **HDFS如何保证数据不丢失?** 

   数据的完整性：

   由于存储设备故障等原因，存储在 DataNode 上的数据块也会发生损坏。为了避免读取到已经损坏的数据而导致错误，HDFS 提供了数据完整性校验机制来保证数据的完整性，具体操作如下：

   当客户端创建 HDFS 文件时，它会计算文件的每个块的 `校验和`，并**将 `校验和` 存储在同一 HDFS 命名空间下的单独的隐藏文件中**。当客户端检索文件内容时，它会验证从每个 DataNode 接收的数据是否与存储在关联校验和文件中的 `校验和` 匹配。如果匹配失败，则证明数据已经损坏，此时客户端会选择从其他 DataNode 获取该块的其他可用副本。

10. **HDFS NameNode高可用如何实现?需要哪些角色?**  

11. **HDFS的文件结构?** 

12. **HDFS的默认副本数?为什么是这个数量?如果想修改副本数怎么修改?** 

13. **介绍下HDFS的Block** 

14. **HDFS的块默认大小，64M和128M是在哪个版本更换的?怎么修改默认块大小?**  

15. **HDFS的block为什么是128M?增大或减小有什么影响?**  

16. **NameNode HA的实现原理？如何避免NameNode脑裂的情况？**

    > HA实现原理：
    >
    > 1. **Namespace同步**：**Standby NameNode通过不断地从Active NameNode获取编辑日志，以及周期性地从共享存储加载文件系统镜像**，来保持自身元数据的与Active NameNode的同步。Standby NameNode将这些元数据应用于自身的**命名空间**，以确保它与Active NameNode的命名空间保持一致。
    > 2. **共享存储**：Active和Standby NameNode之间需要共享存储来同步文件系统的元数据。通常使用共享的持久性存储，例如**NFS（Network File System）**或共享的分布式文件系统，将元数据的编辑日志（Edit Log）和文件系统镜像（FsImage）存储在共享存储上。Edit Log记录了对文件系统的变更操作，而FsImage是文件系统的快照。
    > 3. **ZK选举和自动切换**：HA集群中，Active和Standby NameNode之间**通过心跳信号进行通信，以检测彼此的健康状态**。如果Active NameNode无法发送心跳，或者Standby NameNode检测到Active NameNode的故障，它将启动一个选举过程，以选举新的Active NameNode。选举的结果会被广播给所有集群成员，以确保它们知道新的Active NameNode。一旦新的Active NameNode选举完成，Standby NameNode切换为Active状态，并开始处理客户端请求。
    >
    > 如何避免NameNode脑裂（ZK选主）：
    >
    > 1. "脑裂"是在分布式系统中一个常见的问题，特别是在主备（master/standby）架构中，这种现象可能会发生。**当两个或多个节点都认为自己是主节点时，就会发生"脑裂"现象。**这可能会导致数据不一致或数据丢失。
    >
    > 2. 在Hadoop HDFS中，NameNode是一个关键组件，它负责管理文件系统的元数据，同时也是客户端访问文件的入口点。在早期的Hadoop版本中，NameNode是单点故障（Single Point of Failure），如果它崩溃了，整个HDFS就会不可用。为了解决这个问题，后续的Hadoop版本引入了主备（Active/Standby）NameNode配置。
    >
    > 3. 为了避免NameNode的"脑裂"现象，Hadoop 2.0 引入了**ZooKeeper用于选举和故障切换**。在主备架构中，只有一个NameNode处于活动状态，另一个处于备用状态。使用ZooKeeper来管理哪个节点应该是活动的，以及当活动节点故障时进行故障切换。ZooKeeper是一个开源的，用于维护配置信息，命名，提供分布式同步，组服务等的分布式应用程序协调服务。它提供了一种高效且可靠的**分布式锁服务，这正是我们用来解决"脑裂"问题所需的。**如果主NameNode出现故障，ZooKeeper将检测到这一点并开始选举新的主NameNode，然后备用NameNode就会接管，并从编辑日志中加载最新的文件系统元数据状态。这个过程对客户端来说是透明的，虽然在故障切换期间，客户端的请求可能会被暂时阻塞。
    >
    > 所以，使用ZooKeeper进行主节点选举和故障转移，可以避免Hadoop HDFS中NameNode的"脑裂"现象。

17. **导入大文件到HDFS时如何自定义分片?** 

18. **HDFS的mapper和reducer的个数如何确定?reducer的个数依据是什么?**  

19. **HDSF通过那个中间组件去存储数据** 

20. **HDFS跨节点怎么进行数据迁移** 

21. **HDFS的数据-致性靠什么保证?**  

22. **HDFS怎么保证数据安全** 

23. **HDFS中向DataNode写数据失败了怎么办**  

24. **Hadoop2.xHDFS快照**  

25. **HDFS文件存储的方式?** 

26. **HDFS写数据过程，写的过程中有哪些故障，分别会怎么处理?**  

27. **NameNode存数据吗?** 

28. **使用NameNode的好处** 

29. **HDFS中DataNode怎么存储数据的** 

30. **直接将数据文件上传到HDFS的表目录中，如何在表中查询到该数据?** 

31. **secondary namenode工作机制（☆☆☆☆☆）**

    ![image-20220824172846360](https://springboot-vue-blog.oss-cn-hangzhou.aliyuncs.com/img-for-typora/image-20220824172846360.png)

    1）第一阶段：nameNode启动

    1. 第一次启动NameNode格式化后，创建**fsimage和edits文件**。如果不是第一次启动，直接加载**镜像文件和编辑日志**到内存。
    2. 客户端对**元数据**进行增删改的请求
    3. nameNode记录操作日志，更新滚动日志
    4. nameNode在内存中对数据进行增删改查

    2）第二阶段：Secondary NameNode工作

    1. Secondary NameNode询问nameNode是否需要checkpoint。直接带回是否checkpoint结果。
    2. Secondary NameNode请求执行checkpoint。
    3. nameNode滚动正在写的edits日志。
    4. **将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。**
    5. **Secondary NameNode加载编辑日志和镜像文件到内存，并合并。**
    6. 生成新的镜像文件fsimage.chkpoint。
    7. 拷贝fsimage.chkpoint到NameNode。
    8. NameNode将fsimage.chkpoint重新命名成fsimage。

    > 总之就是：每次NameNode都使用**编辑日志和Secondary NameNode生成的镜像文件**，对数据进行增删改查。
    >
    > Secondary NameNode生成的镜像文件就可以很好的帮助NameNode分担压力和崩溃时的恢复。