1. **HDFS文件写入和读取流程**  （☆☆☆☆☆）

   * **HDFS写数据过程**

     ![image-20220824172938620](https://springboot-vue-blog.oss-cn-hangzhou.aliyuncs.com/img-for-typora/image-20220824172938620.png)

   1）客户端通过分布式文件系统Distributed FileSystem模块向nameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。

   2）nameNode返回是否可以上传。

   3）客户端请求第一个block上传到哪几个datanode服务器上。

   4）NameNode返回3个datanode节点，分别为dn1、dn2、dn3。

   5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。

   6）dn1、dn2、dn3逐级应答客户端。

   7）客户端开始往dn1上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，dn1收到一个packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。

   8）当一个block传输完成之后，客户端再次请求NameNode上传第二个block到服务器。（重复执行3~7步）

   * **HDFS读数据流程**

     ![image-20220824172950541](https://springboot-vue-blog.oss-cn-hangzhou.aliyuncs.com/img-for-typora/image-20220824172950541.png)

   1）客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件快所在的DataNode地址。

   2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。

   3）dataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以packet为单位来做校验）。

   4）客户端以packet为单位接收，先在本地缓存，然后写入目标文件。

2. **HDFS组成架构** （☆☆☆☆☆）

   ![image-20220824172912456](https://springboot-vue-blog.oss-cn-hangzhou.aliyuncs.com/img-for-typora/image-20220824172912456.png)

   架构主要由四部分组成：**HDFS Client、NameNode、DataNode和Secondary NameNode**

   1）HDFS Client：客户端

   1. 文件切分。文件上传HDFS的时候，Client将文件切分成一个个的block，然后进行存储；
   2. 与nameNode交互，获取文件的位置信息；
   3. 与dataNode交互，读取或者写入数据；
   4. Client提供一些命令来管理HDFS,比如启动或者关闭HDFS
   5. Client可以通过一些命令来访问HDFS；

   2）nameNode：就是master，他是一个主管、管理者。

   1. 管理HDFS的名称空间；
   2. 管理数据块（Block）映射信息；
   3. 配置副本策略；
   4. 处理客户端读写请求。

   3）DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。

   1. 存储实际的数据块；
   2. 执行数据块的读/写操作。

   4）Secondary NameNode：**并非**NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。

   1. 辅助nameNode，分担其工作量
   2. 定期合并Fsimage和Edits，并推送给NameNode
   3. 在紧急情况下，可辅助恢复NameNode。

3. **介绍下HDFS，说下HDFS优缺点，以及使用场景**  

4. **HDFS作用** 

5. **HDFS的容错机制**  

   文件系统的容错可以通过NameNode高可用、SecondaryNameNode机制、数据块副本机制和心跳机制来实现

   ~~~
   注意：当以本地模式或者伪集群模式部署 Hadoop 时，会存在 SeconddayNameNode；当以集群模式部署 Hadoop 时，如果配置了 NameNode 的 HA 机制，则不会存在 SecondaryNameNode，此时会存在备 NameNode。
   ~~~

   **读容错**和**写容错**机制的流程如下：

   1）备用nameNode实时备份主NameNode上的元数据信息，一旦朱NameNode发生故障不可用，则备 NameNode 迅速接管主 NameNode 的工作。

   2）客户端向 DataNode 读取/写入 数据，此时会分为读取数据和写入数据两种情况。

   1. 读取数据：HDFS会检测文件快的完整性，确认文件块的**检验和**与DataNode中是否一致，如果不一致，则从其他的 DataNode 上获取相应的副本。
   2. 写入数据：HDFS 会检测文件块的完整性，最后一个DataNode负责确认**校验和**与客户端发送的校验和是否一致，同时记录新创建的文件的所有文件块的校验和。

   3）DataNode会定期向NameNode发送心跳信息，将自身节点的状态告知NameNode；NameNode会将DataNode 需要执行的命令放入心跳信息的返回结果中，返回给 DataNode 执行。

   ​	   当 DataNode 发生故障没有正常发送心跳信息时，NameNode 会检测文件块的副本数是否小于 系统设置值，如果小于设置值，则自动复制新的副本并分发到其他的 DataNode 上。

   4）集群中有数据关联的 DataNode 之间复制数据副本。

   ​		当集群中的 DataNode 发生故障而失效，或者在集群中添加新的 DataNode 时，可能会导致数据分布**不均匀**。当某个 DataNode 上的空闲空间资源大于系统设置的临界值时，HDFS 就会从 其他的 DataNode 上将数据迁移过来。相对地，如果某个 DataNode 上的资源出现超负荷运载，HDFS 就会根据一定的规则寻找有空闲资源的 DataNode，将数据迁移过去。

   ​	还有一种从侧面说明 HDFS 支持容错的机制，即当从 HDFS 中删除数据时，数据并不是马上就会从 HDFS 中被删除，而是会将这些数据放到“回收站”目录中，随时可以恢复，直到超过了一定的时间才会真正删除这些数据。

6. **HDFS的存储机制**  

   1）[HDFS](https://so.csdn.net/so/search?q=HDFS&spm=1001.2101.3001.7020)设计出一套文件存储方式，即对文件分割后分别存放；

   2）Block（块）是HDFS的基本存储单元，默认大小是64M；

   3）NameNode存储HDFS文件元数据，DataNode存储实际数据；

   4）通过副本机制对已经存储的Block进行备份，这样可以快速恢复损坏的数据；

7. **HDFS的副本机制** 

       HDFS 会将数据文件切分成一个个小的数据块进行存储，同时会将这些数据块的副本保存多份，分别保存到不同的 DataNode 上。HDFS 中数据块的副本数由 hdfs-site.xml文件中的dfs.replication属性决定。
       Hadoop 默认的副本数为3，并且在机架的存放上也有一定的策略。Hadoop 的默认布局策略，即默认的副本存放策略如下：
   
          （1）第 1 个副本存放在 HDFS 客户端所在的节点上。
       
          （2）第 2 个副本存放在与第1个副本不同的机架上，并且是随机选择的节点。
          
          （3）第 3 个副本存放在与第2个副本相同的机架上，并且是不同的节点。


8. **HDFS的常见数据格式，列式存储格式和行存储格式异同点，列式存储优点有哪些?**  

   解答见HDFS目录。

9. **HDFS如何保证数据不丢失?** 

   数据的完整性：

   由于存储设备故障等原因，存储在 DataNode 上的数据块也会发生损坏。为了避免读取到已经损坏的数据而导致错误，HDFS 提供了数据完整性校验机制来保证数据的完整性，具体操作如下：

   当客户端创建 HDFS 文件时，它会计算文件的每个块的 `校验和`，并**将 `校验和` 存储在同一 HDFS 命名空间下的单独的隐藏文件中**。当客户端检索文件内容时，它会验证从每个 DataNode 接收的数据是否与存储在关联校验和文件中的 `校验和` 匹配。如果匹配失败，则证明数据已经损坏，此时客户端会选择从其他 DataNode 获取该块的其他可用副本。

10. **HDFS NameNode高可用如何实现?需要哪些角色?**  

11. **HDFS的文件结构?** 

12. **HDFS的默认副本数?为什么是这个数量?如果想修改副本数怎么修改?** 

13. **介绍下HDFS的Block** 

14. **HDFS的块默认大小，64M和128M是在哪个版本更换的?怎么修改默认块大小?**  

15. **HDFS的block为什么是128M?增大或减小有什么影响?**  

16. **HDFS HA怎么实现?是个什么架构?** 

17. **导入大文件到HDFS时如何自定义分片?** 

18. **HDFS的mapper和reducer的个数如何确定?reducer的个数依据是什么?**  

19. **HDSF通过那个中间组件去存储数据** 

20. **HDFS跨节点怎么进行数据迁移** 

21. **HDFS的数据-致性靠什么保证?**  

22. **HDFS怎么保证数据安全** 

23. **HDFS中向DataNode写数据失败了怎么办**  

24. **Hadoop2.xHDFS快照**  

25. **HDFS文件存储的方式?** 

26. **HDFS写数据过程，写的过程中有哪些故障，分别会怎么处理?**  

27. **NameNode存数据吗?** 

28. **使用NameNode的好处** 

29. **HDFS中DataNode怎么存储数据的** 

30. **直接将数据文件上传到HDFS的表目录中，如何在表中查询到该数据?** 

31. **secondary namenode工作机制（☆☆☆☆☆）**

    ![image-20220824172846360](https://springboot-vue-blog.oss-cn-hangzhou.aliyuncs.com/img-for-typora/image-20220824172846360.png)

    1）第一阶段：nameNode启动

    1. 第一次启动NameNode格式化后，创建fsimage和edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。
    2. 客户端对**元数据**进行增删改的请求
    3. nameNode记录操作日志，更新滚动日志
    4. nameNode在内存中对数据进行增删改查

    2）第二阶段：Secondary NameNode工作

    1. Secondary NameNode询问nameNode是否需要checkpoint。直接带回是否checkpoint结果。
    2. Secondary NameNode请求执行checkpoint。
    3. nameNode滚动正在写的edits日志。
    4. 将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。
    5. Secondary NameNode加载编辑日志和镜像文件到内存，并合并。
    6. 生成新的镜像文件fsimage.chkpoint。
    7. 拷贝fsimage.chkpoint到NameNode。
    8. NameNode将fsimage.chkpoint重新命名成fsimage。

32. **HANameNode（High Availability高可用）是如何工作的**

    ​	ZKFailoverController主要职责

    1）健康检测：周期性的向它监控的NN发送健康检测命令，从而来确定某个NameNode是否处于健康状态，如果机器宕机，心跳失败，那么zkfc就会标记它处于一个不健康的状态。

    2）会话管理：如果NN是健康的，zkfc就会在zookeeper中保持一个打开的会话，如果NameNode同时还是Active状态的，那么zkfc还会在Zookeeper中占有一个类型为短暂类型的znode，当这个NN挂掉时，这个znode将会被删除，然后备用的NN，将会得到这把锁，升级为主NN，同时标记状态为Active。

    3）当宕机的NN新启动时，它会再次注册zookeper，发现已经有znode锁了，便会自动变为Standby状态，如此往复循环，保证高可靠，需要注意，目前仅仅支持最多配置2个NN。

    4）master选举：如上所示，通过在zookeeper中维持一个短暂类型的znode，来实现抢占式的锁机制，从而判断哪个NameNode为Active状态