#### 1. Hadoop中Context类

  简单的说顶级接口是为了在map或是reduce任务中跟踪task的状态，很自然的MapContext就是记录了map执行的上下文，在mapper类中，这个context可以存储一些job conf的信息，比如习题一中的运行时参数等，我们可以在map函数中处理这个信息，这也是hadoop中参数传递中一个很经典的例子，同时context作为了map和reduce执行中各个函数的一个桥梁，这个设计和java web中的session对象、application对象很相似。

#### 2. Map函数和Reduce函数调用的时间

  map函数：如果切片规则是**TextInputFormat**，则**每条记录**调用一次；

  Reduce函数：在ReduceTask任务完成内存和磁盘上数据进行统一的归并排序之后，对**相同的key**调用一次

#### 3. 数据切片与MapTask并行度 

  > MapTask 并行度由切片个数决定，切片个数由**输入文件和切片规则**决定。

> 常用的FileInputFormat 类：

1. TextInputFormat 是默认的 FileInputFormat 实现类。**按行**读取每条记录。

2. 键是存储该行在整个文件中的起始字符偏移量， LongWritable 类型。

   值是这行的内容，不包括任何行终止 符（换行符和回车符），Text 类型。

3. CombineTextInputFormat 可以把多个小文件合并成一个切片处理，提高处理效率。

> FileInputFormat切片机制：

1. 程序先找到你数据存储的目录。

2. 计算切片大小，默认情况下：computeSplitSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M

   mapreduce.input.fileinputformat.split.minsize=1 默认值为1

   mapreduce.input.fileinputformat.split.maxsize= Long.MAXValue 默认值Long.MAXValue

   因此，默认情况下，切片大小=blocksize

3. 每次切片时，都要判断切完剩下的部分是否大于块的1.1倍，不大于1.1倍就划分一块切片

4. 将切片信息写到一个切片规划文件中

5. 整个切片的核心过程在getSplit()方法中完成

6. InputSplit只记录了切片的元数据信息，比如起始位置、长度以及所在的节点列表等。

7. 提交切片规划文件到**YARN**上，**YARN上的MrAppMaster**就可以根据切片规划文件计算开启MapTask个数。

8. 获取切片信息API

   ~~~java
   // 根据文件类型获取切片信息
   FileSplit inputSplit = (FileSplit) context.getInputSplit();
   // 获取切片的文件名称
   String name = inputSplit.getPath().getName();
   ~~~

#### 4. Combiner

  父类是Reducer。在**map端，Reduce操作前**对相同key的键值对，进行初步合并操作，以**减少网络传输**数据量。

#### 5. partitioner

  默认分区是根据key的hashCode对ReduceTasks个数取模得到的。用户没法控制哪个 key存储到哪个分区。

  分区时会先判断ReduceTask个数，如果=1，不会执行分区。

#### 6. WritableComparable 排序

> 排序概述：

1. 排序是MapReduce框架中最重要的操作之一。 MapTask和ReduceTask均会对数据**按照key**进行排序。

   该操作属于 Hadoop的默认行为。任何应用程序中的数据均会被排序，而不管逻辑上是否需要。

> 排序分类：

1. 全排序：最终输出结果只有一个文件，且文件内部有序。实现方式是只设置一个ReduceTask。但该方法在 处理大型文件时效率极低，因为一台机器处理所有文件，完全丧失了MapReduce所提供的并行架构。

2. 部分排序：先按照**分区编号**Partition进行排序，再根据**输入记录的键**对数据集排序。保证输出的每个文件内部有序。

3. 辅助排序：（GroupingComparator分组） 在Reduce端对key进行分组。应用于：在接收的key为bean对象时，想让一个或几个字段相同（全部 字段比较不相同）的key进入到同一个reduce方法时，可以采用分组排序。

4. 二次排序：在**自定义排序**过程中，如果compareTo中的判断条件为两个即为二次排序。

> 排序发生的时间：

1. 对于MapTask。环形缓冲区存放的Map函数输出满80%后，溢写数据到磁盘时。发生**一次快速排序**，生成一个小文件。多次溢写后，对生成的多个小文件进行**一次归并排序**。

2. 对于ReduceTask。它从每个MapTask上远程拷贝相应的数据文件。

   如果文件大小超过一定阈值，则溢写到磁盘上，否则存储在内存中；

   如果磁盘上文件数量达到一定阈值，则进行**一次归并排序**以生成一个更大文件；

   如果内存中文件大小或者数量超过一定阈值，则进行**一次归并排序**后溢写到磁盘；

   当所有数据拷贝完之后，ReduceTask**统一**对内存和磁盘上的所有数据进行**一次归并排序**。

  ```
  Writable接口，可实现自定义序列化类型。
  WritableComparable接口，可实现自定义排序。
  ```

#### 7. Join应用

> Reduce Join

1. Map端的主要工作：用链接字段作为输出key，其余部分和**新加的标记字段**作为value，进行输出。标记字段是用来区别该条记录来源于哪张表。

2. Reduce端的主要工作：在执行Reduce函数之前，以连接字段作为key的分组（归并排序）已经完成。我们只需要对每个相同key的分组【类似于<1,orderBean><1,PdBean><key,value><key,value><...,...>】进行合并。

  即区分开来源于不用表的记录，然后用需求中的主表(OrderBean)作为结果集合的一条记录，再向该记录添加子表(PdBean)的字段即可。

3. Reduce Join的缺点：

   (1)合并操作在Reduce端处理，**Reduce压力太大**。Map端运算负载很低，**资源利用率不高**。

   (2)关联条件成立的数据，在各个Reduce任务中的分布可能会有很大差别：比如订单表中pid为01的数据占90%，那么合并操作都会大量倾斜在处理输入key为01的Reduce任务上。则很容易产生了**数据倾斜**。

> Map Join

1. 适用场景：Map Join 适用于一张表十分小、一张表很大的场景。

2. 优点：

   思考：在 Reduce 端处理过多的表，非常容易产生数据倾斜。怎么办？

   在**Map端将小表缓存**，提前处理业务逻辑，这样**增加Map端业务**。由于是按照大表切片，则可以把合并操作**均匀的分布**在各个Map任务【**因为MapTask的并发数由切片数决定**】。

   从而可以有效减少Reduce端数据压力，尽可能的减少数据倾斜。

3. 具体办法：采用 **DistributedCache**

   （1）在 Mapper 的 setup 阶段，将**文件读取到缓存集合(如HashMap)**中。 

   （2）在 Driver 驱动类中加载缓存。

   ​			**job.addCacheFile(new URI(""));**

#### 8. 数据压缩

> 压缩原则：

（1）运算密集型的 Job，少用压缩 

（2）IO 密集型的 Job，多用压缩

> 压缩方式:

​	DEFAULT,GZIP,bZIP2(支持切片),LZO(支持切片),SNAPPY。

> 压缩选择：

压缩方式选择时重点考虑：压缩/解压缩速度、压缩率（压缩后存储大小）、压缩后是否 可以支持切片。

---

