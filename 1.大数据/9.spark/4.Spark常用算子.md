#### Transformation 和 Action 常用算子

> 具体来说，Spark 中的算子可以分为两种类型：转换算子（Transformation）和动作算子（Action）。转换算子是用于对 RDD、DataFrame 或 Dataset 进行转换操作的算子，它们并不会触发任务的执行，而只是**返回一个新的 RDD、DataFrame 或 Dataset 对象**。而动作算子是用于触发任务执行的算子，它们会将数据从存储介质（如 HDFS、HBase、Kafka 等）读取到 Executor 中，进行计算并输出结果。
>
> 在Spark Streaming中，DStream（Discretized Stream）是一种高级抽象，它表示一个连续的数据流。DStream可以理解为一系列连续的RDD（Resilient Distributed Dataset），每个RDD都包含了一段时间内的数据。
>
> **每个 DStream 都可以看作是一系列的 RDD，这些 RDD 按照时间间隔生成。**每个 RDD 可以在 Spark 集群中的不同节点上进行并行处理。当你在 DStream 上定义转换操作（例如 `transform` 和 `map`）时，这些操作会在每个生成的 RDD 上执行。而每个 RDD 可能会被划分为多个分区，这些分区会被分配到集群中的不同节点上执行。因此，**针对每个 DStream**，**Spark 会根据其生成的 RDD 和分区来创建多个任务分配到各个节点上。**
>
> 在对**同一个Dstream流**编写 Spark 代码时，需要注意：
>
> 1. **转换算子在 Spark 中通常是惰性执行的，这意味着在遇到动作操作（action）之前，它们不会触发spark任务的执行。转换操作定义了数据转换的逻辑，并创建了一个新的 RDD，它在逻辑上表示了转换操作的结果。然而，实际的数据处理和转换发生在动作操作触发时，由 executor 端执行。**在遇到动作操作之前，转换算子主要在 driver 端构建一个**执行计划**，它们不会处理数据。一旦触发了动作操作，计划中的所有转换操作将按顺序在 executor 端执行，以完成数据处理和转换。
>
>    **如果该Dstream流中只有一个转换操作，永远不会遇到动作操作（action），那么这个转换算子中的代码只会在driver端执行，而针对RDD生成的执行计划，永远不会被执行。**
>
> 2. **对于动作算子，代码会在 Executor 程序中执行，因为动作算子会触发任务的执行**，并将数据从存储介质中读取到 Executor 中进行计算。此时，需要注意对数据的处理和存储，以免出现数据倾斜或存储过程中的性能瓶颈。
>
> 3. 在执行任务时，可以通过 Spark Web UI 来监控任务的执行情况，包括任务的调度、执行时间、内存使用情况等。
>
> 总之，在编写 Spark 代码时，需要根据具体的业务需求，选择合适的算子类型，并注意代码的执行环境，以保证代码的正确性和性能。

一、Transformation



二、Action