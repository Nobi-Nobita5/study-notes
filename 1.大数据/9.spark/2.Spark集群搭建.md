~~~
https://blog.csdn.net/u011109589/article/details/124855282?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165966874616782388044861%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=165966874616782388044861&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-124855282-null-null.142^v39^pc_rank_v38,185^v2^control&utm_term=%E6%90%AD%E5%BB%BAspark%E9%9B%86%E7%BE%A4&spm=1018.2226.3001.4187
~~~

成功搭建了Standalone 模式 和 yarn模式；

1. **Standalone 模式**：

​		只使用 Spark 自身节点运行的集群模式，也就是我们所谓的独立部署（Standalone）模式。

2. **yarn模式**（现已搭建，/conf目录下的配置文件参考上述链接）

   上面默认是用standalone模式启动的服务，如果想要把资源调度交给yarn来做，则需要配置为yarn模式：
   需要启动的服务：**hdfs**服务、yarn服务
   需要**关闭 Standalone** 对应的服务(即集群中的Master、Worker进程)。
   在Yarn模式中，Spark应用程序有两种运行模式：
   **yarn-client**：Driver程序运行在客户端，适用于交互、调试，希望立即看到app的输出
   **yarn-cluster**：Driver程序运行在由RM启动的 AppMaster中，适用于生产环境
   二者的主要区别：Driver在哪里。



`spark-shell --master local[4]`是本地模式，主要用于学习
