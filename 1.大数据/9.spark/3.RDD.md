> SparkCore文档

#### 一、什么是RDD

RDD（Resilient Distributed Datasets，弹性分布式数据集）是Apache Spark的核心数据结构。代码中是一个抽象类，RDD具有以下几个关键特性：

1. **弹性（Resilient）**： **弹性是指RDD具有容错能力**。这意味着，如果在计算过程中发生故障，例如节点故障，RDD可以自动从其他节点上的副本中恢复数据。**RDD通过数据分区及其元数据信息（称为血统信息）来实现容错**。血统信息包含了从原始数据到当前RDD的所有转换操作，因此在发生故障时，Spark可以通过血统信息重新计算丢失的分区，而不是从头开始重新计算整个数据集。
2. **不可变（Immutable）**： **RDD是不可变的数据结构**，这意味着一旦创建，RDD的内容无法更改。这个特性使得RDD适合在分布式环境中进行并行计算，因为不需要担心数据在多个节点之间的同步问题。所有对RDD的操作都会生成一个新的RDD，保留原始RDD的内容。这种不可变性有助于简化编程模型，提高可靠性，并使得Spark可以在内部优化计算过程。
3. **可分区（Partitioned）**： **RDD的数据是分区存储的，即数据会被分割成多个分区，每个分区可以独立进行计算**。这种分区结构允许Spark在不同的节点上并行处理数据。分区的**数量可以根据实际情况进行手动调整**，以便在不同的集群规模和硬件配置下获得最佳性能。
4. **可并行计算（Parallelizable）**： **RDD的设计允许在多个节点上同时处理数据。由于数据是分区存储的，Spark可以将计算任务分发到集群中的多个节点，使每个节点处理一个或多个分区**。这种并行计算模型可以大大提高计算速度，特别是在处理大规模数据时。此外，Spark会根据集群资源状况动态调整任务并行度，以实现最佳性能。

这些特性使得RDD成为一个适用于分布式计算环境的强大数据结构。通过RDD，Spark可以有效地处理大规模数据，并提供高性能、容错和易用性等优点。

> 在Spark中，**一个RDD分区只存在于一个节点上，不会被复制到其他节点上**。

#### 二、核心属性

1. 分区列表
2. 分区计算函数
3. RDD之间的依赖关系
4. 分区器
5. 首选位置

#### 三、执行原理

从计算的角度来看，数据处理需要**计算资源（内存 & CPU）和计算模型（逻辑）**

在yarn环境中，RDD的工作原理：

1. 启动yarn集群环境
2. Spark通过申请资源创建**调度节点**和**计算节点**
3. Spark框架根据需求将**计算逻辑**根据**分区**划分成**不同任务**
4. 调度节点将任务根据计算节点状态发送到对应的计算节点进行计算 

可以看出RDD主要用于封装逻辑，生成**Task**发送给**Executor**节点执行计算。

#### 四、创建RDD

1. 由现有集合创建
2. 引用外部存储系统中的数据集创建
3.  textFile & wholeTextFiles

#### 五、操作RDD

​	RDD支持两种类型的操作：transformations（转换，从现有数据集创建新数据集）和actions（在数据集上运行计算后将值返回到驱动程序）。RDD中的所有转换都是惰性的，他们只是记住这些转换操作，但不会立即执行，只有遇到action操作后才会真正的进行计算，这类似于函数式编程中的惰性求值。

~~~
val list = List(1, 2, 3)
// map 是一个 transformations 操作，而 foreach 是一个 actions 操作
sc.parallelize(list).map(_ * 10).foreach(println)
// 输出： 10 20 30
~~~

#### 六、缓存RDD

​	Spark速度快的原因之一是支持缓存。缓存成功后，如果之后的操作使用到了该数据集，则直接从缓存中获取。虽然缓存也有丢失的风险，但是由于 RDD 之间的依赖关系，如果某个分区的缓存数据丢失，只需要重新计算该分区即可。

1. Spark 支持多种缓存级别 ：

2. 使用缓存：`persist`和`cache`

3. 移除缓存

   Spark 会自动监视每个节点上的缓存使用情况，并按照最近最少使用（LRU）的规则删除旧数据分区。当然，你也可以使用 `RDD.unpersist()` 方法进行手动删除。

#### 七、理解shuffle

	1. shuffle介绍
	1. shuffle的影响
	1. 导致shuffle的操作

#### 八、宽依赖和窄依赖

RDD 和它的父 RDD(s) 之间的依赖关系分为两种不同的类型：

- **窄依赖 (narrow dependency)**：父 RDDs 的一个分区最多被子 RDDs 一个分区所依赖；
- **宽依赖 (wide dependency)**：父 RDDs 的一个分区可以被子 RDDs 的多个子分区所依赖。

#### 九、DAG(有向无环图)的生成

​	RDDs之间的依赖关系组成了DAG，如果一个RDD的部分或者全部计算丢失了，也可以重新计算。Spark主要根据依赖关系将不同的DAG划分为不同的计算阶段来生成计算任务。

- 对于窄依赖，由于分区的依赖关系是确定的，其转换操作可以在同一个线程执行，所以可以划分到同一个执行阶段；
- 对于宽依赖，由于 Shuffle 的存在，只能在父 RDD(s) 被 Shuffle 处理完成后，才能开始接下来的计算，因此遇到宽依赖就需要重新划分阶段。