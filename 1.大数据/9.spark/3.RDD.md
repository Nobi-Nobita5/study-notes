> SparkCore文档

#### 一、什么是RDD

RDD（Resilient Distributed Datasets，弹性分布式数据集）是Apache Spark的核心数据结构。代码中是一个抽象类，RDD具有以下几个关键特性：

1. **弹性（Resilient）**： **弹性是指RDD具有容错能力**。这意味着，如果在计算过程中发生故障，例如节点故障，RDD可以自动从其他节点上的副本中恢复数据。**RDD通过数据分区及其元数据信息（称为血统信息）来实现容错**。血统信息包含了从原始数据到当前RDD的所有转换操作，因此在发生故障时，Spark可以通过血统信息重新计算丢失的分区，而不是从头开始重新计算整个数据集。
2. **不可变（Immutable）**： **RDD是不可变的数据结构**，这意味着一旦创建，RDD的内容无法更改。这个特性使得RDD适合在分布式环境中进行并行计算，因为不需要担心数据在多个节点之间的同步问题。所有对RDD的操作都会生成一个新的RDD，保留原始RDD的内容。这种不可变性有助于简化编程模型，提高可靠性，并使得Spark可以在内部优化计算过程。
3. **可分区（Partitioned）**： **RDD的数据是分区存储的，即数据会被分割成多个分区，每个分区可以独立进行计算**。这种分区结构允许Spark在不同的节点上并行处理数据。分区的**数量可以根据实际情况进行手动调整**，以便在不同的集群规模和硬件配置下获得最佳性能。
4. **可并行计算（Parallelizable）**： **RDD的设计允许在多个节点上同时处理数据。由于数据是分区存储的，Spark可以将计算任务分发到集群中的多个节点，使每个节点处理一个或多个分区**。这种并行计算模型可以大大提高计算速度，特别是在处理大规模数据时。此外，Spark会根据集群资源状况动态调整任务并行度，以实现最佳性能。

这些特性使得RDD成为一个适用于分布式计算环境的强大数据结构。通过RDD，Spark可以有效地处理大规模数据，并提供高性能、容错和易用性等优点。

> **RDD分区副本：**
>
> 在 Spark 中，RDD 分区默认情况下是不包含副本的。每个 RDD 分区只有一个副本，且在一个 executor 上处理。然而，Spark 提供了一种叫做“数据备份”或“RDD持久化”的机制，它允许你以不同的存储级别缓存 RDD。
>
> 通过使用 `persist()` 或 `cache()` 方法，并选择合适的存储级别，例如 `StorageLevel.MEMORY_AND_DISK_2`，你可以要求 Spark 为 RDD 分区创建多个副本。这种情况下，当一个节点失败时，Spark 可以从另一个节点上的副本中恢复数据，而不是重新计算整个分区，从而提高容错能力和性能。
>
> 需要注意的是，使用 RDD 持久化和创建多个副本会增加内存和存储的开销。因此，在选择存储级别时，应权衡性能和资源消耗。

#### 二、核心属性

1. 分区列表
2. 分区计算函数
3. RDD之间的依赖关系
4. 分区器
5. 首选位置

#### 三、执行原理

从计算的角度来看，数据处理需要**计算资源（内存 & CPU）和计算模型（逻辑）**

在yarn环境中，RDD的工作原理：

1. 启动yarn集群环境
2. Spark通过申请资源创建**调度节点**和**计算节点**
3. Spark框架根据需求将**计算逻辑**根据**分区**划分成**不同任务**
4. 调度节点将任务根据计算节点状态发送到对应的计算节点进行计算 

可以看出RDD主要用于封装逻辑，生成**Task**发送给**Executor**节点执行计算。

#### 四、创建RDD

1. 由现有集合创建
2. 引用外部存储系统中的数据集创建
3.  textFile & wholeTextFiles

#### 五、操作RDD

​	RDD支持两种类型的操作：transformations（转换，从现有数据集创建新数据集）和actions（在数据集上运行计算后将值返回到驱动程序）。RDD中的所有转换都是惰性的，他们只是记住这些转换操作，但不会立即执行，只有遇到action操作后才会真正的进行计算，这类似于函数式编程中的惰性求值。

~~~
val list = List(1, 2, 3)
// map 是一个 transformations 操作，而 foreach 是一个 actions 操作
sc.parallelize(list).map(_ * 10).foreach(println)
// 输出： 10 20 30
~~~

#### 六、缓存RDD

​	Spark速度快的原因之一是支持缓存。缓存成功后，如果之后的操作使用到了该数据集，则直接从缓存中获取。虽然缓存也有丢失的风险，但是由于 RDD 之间的依赖关系，如果某个分区的缓存数据丢失，只需要重新计算该分区即可。

1. Spark 支持多种缓存级别 ：

2. 使用缓存：`persist`和`cache`

3. 移除缓存

   Spark 会自动监视每个节点上的缓存使用情况，并按照最近最少使用（LRU）的规则删除旧数据分区。当然，你也可以使用 `RDD.unpersist()` 方法进行手动删除。

#### 七、理解shuffle

	1. shuffle介绍
	1. shuffle的影响
	1. 导致shuffle的操作

#### 八、宽依赖和窄依赖

RDD 和它的父 RDD(s) 之间的依赖关系分为两种不同的类型：

- **窄依赖 (narrow dependency)**：父 RDDs 的一个分区最多被子 RDDs 一个分区所依赖；
- **宽依赖 (wide dependency)**：父 RDDs 的一个分区可以被子 RDDs 的多个子分区所依赖。

#### 九、DAG(有向无环图)的生成

​	RDDs之间的依赖关系组成了DAG，如果一个RDD的部分或者全部计算丢失了，也可以重新计算。Spark主要根据依赖关系将不同的DAG划分为不同的计算阶段来生成计算任务。

- 对于窄依赖，由于分区的依赖关系是确定的，其转换操作可以在同一个线程执行，所以可以划分到同一个执行阶段；
- 对于宽依赖，由于 Shuffle 的存在，只能在父 RDD(s) 被 Shuffle 处理完成后，才能开始接下来的计算，因此遇到宽依赖就需要重新划分阶段。

#### 十、用一个例子，介绍说明下Spark的宽依赖窄依赖，血缘关系，以及DAG的构建过程

我们以一个简单的例子来说明 Spark 的宽依赖、窄依赖、血缘关系和 DAG 的构建过程。

假设我们有一个数据文件，其中包含用户的姓名和年龄，我们的任务是找出年龄大于 30 的用户的平均年龄。

首先，我们将使用 Spark 读取文件并创建一个 RDD。

```python
data = sc.textFile("data.txt")
```

然后，我们将每行转换成 (name, age) 的元组。

```python
users = data.map(lambda line: (line.split(",")[0], int(line.split(",")[1])))
```

现在，我们将过滤出年龄大于 30 的用户。

```python
filtered_users = users.filter(lambda x: x[1] > 30)
```

最后，我们将计算这些用户的平均年龄。

```python
sum_age, count = filtered_users.map(lambda x: (x[1], 1)).reduce(lambda x, y: (x[0] + y[0], x[1] + y[1]))
average_age = sum_age / count
```

现在，让我们讨论上面的例子中的概念：

1. **窄依赖**：**窄依赖意味着每个父分区被最多一个子分区使用**。在这个例子中，`data` 到 `users` 和 `users` 到 `filtered_users` 是窄依赖，因为 map 和 filter 操作不需要跨分区交换数据。

2. **宽依赖**：**宽依赖意味着每个父分区可能被多个子分区使用**。在这个例子中，使用了 `reduce` 操作来计算总年龄和总人数。这个 `reduce` 操作是一个宽依赖，因为它需要跨分区收集数据。
3. **血缘关系**：**RDD 的血缘关系信息存储在 Spark 的 Driver 程序的内存中。所以重启Spark应用程序会导致RDD的血缘关系丢失，需要重新构建血缘关系来恢复之前的计算结果。代码现实指定了持久化的RDD可以在重启后直接恢复，而无需重新计算。**血缘关系是指 RDD 通过一系列转换操作从其他 RDD 衍生而来。在我们的例子中，`filtered_users` 的血缘关系包括从 `data` 到 `users` 到 `filtered_users` 的转换。
4. **DAG 构建**：DAG（Directed Acyclic Graph）是一个有向无环图，表示 RDD 之间的依赖关系。在这个例子中，DAG 由三个阶段组成，分别对应于从 `data` 到 `users`，从 `users` 到 `filtered_users` 和计算 `average_age` 的转换。每个阶段由一组窄依赖连接的 RDD 组成，宽依赖标志着阶段的边界。

当我们执行一个 Spark 作业时，Spark 会根据 RDD 的转换和依赖关系构建 DAG，并将其划分为多个阶段，每个阶段包含一系列的任务，这些任务在各个 executor 上并行执行。