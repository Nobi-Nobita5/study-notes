### 1、MapReduce执行流程

### 2、hive执行计划

### 3、hive优化

#### 1）HQL优化

1、建表层面优化

* 使用分区表：根据某个字段去筛选，以该字段为分区字段创建分区表，避免全表扫描
* 文件存储格式：尽量使用ORC、ParquertFile等列式存储格式。每列数据在物理上存储在一起，查询时只需遍历列数据
* 使用分桶表：把数据分为不同类别，将数据以指定列的值为key进行hash，hash到**指定数目的桶中**，筛选时只需遍历桶
* 文件压缩格式：MapReduce的性能瓶颈主要在网络IO和磁盘IO，对数据进行压缩能有效减少数据文件大小

2、语法和参数优化

* 提前过滤数据：列裁剪、谓词下推、分区裁剪
* 参数相关：合并小文件、合理设置Map数Reduce数、压缩参数
* 运行过程相关：防止笛卡尔积、Group By代替Count distinct等

3、架构层面优化

* 启用fetch抓取：简单的SQL可以直接读取对于存储目录下的文件，不用MR计算
* 开启本地执行优化：Hive的输入数据了非常小时，可以通过本地模式在单台机器处理任务，缩短执行时间
* 内存管理：合理分配hive执行过程中的内存资源，包括MR任务的内存配置
* 开启JVM重用：JVM的启动过程可能造成很大开销，开启重用可以使得JVM实例在同一个job中重新使用N次
* 开启并行执行：set hive.exec.parallel=true；当不同stage不完全依赖时，可以同时运行
* 开启Hive严格模式：set hive.mapred.mode = strict；限制 分区表不筛选分区、order by 不带limit、存在笛卡尔积的查询

4、数据倾斜的优化

1）join无关的优化

主要有group by 和 count(distinct)操作引起的倾斜

* group by优化
  * 开启中间数据聚合：设置set hive.map.aggr=true，可以在map阶段进行局部聚合，减少传输到reduce阶段的数据量
  * 二次排序：set hive.groupby.skewindata=true。可以自动检测倾斜的key。在第一个作业将倾斜的key写入一个配置文件，第二个作业将这个数据分成多个小文件，均匀分布到reducer
* count(distinct)优化
  * count(distinct)会导致去重操作在一个节点执行。我们可以用先group by 再count(*)的方法实现去重并计数

2）join相关的优化

* 大表join小表
  * 大小表关联使用map join：小表加载进内存，直接在map端完成join
* 大表join大表（优化方法类似二次排序set hive.groupby.skewindata=true）
  * 第一步：识别出倾斜的键
  * 第二步：处理非倾斜的键
  * 第三步：单独处理倾斜的键（使用map join或者打散热点key再join）
  * 第四步：合并结果

#### 2）bad job衡量指标

1、每个stage（即yarn任务）的Map数指标优化-合理设置MAP数（阈值10000）

* 添加map参数
* 合并小文件
* 大表拆小表
* 全量转增量

2、本地磁盘读写优化（阈值50TB）

超过50TB，1866个DATANODE节点，每个节点有11台SATA盘（50MB/s）。IO时间占用：50X1024X1024/（1866X11X50）=51.09秒

行内存储格式：ORC，解压缩后会扩大7倍左右

* 中间结果压缩
* 复杂字段压缩
* 数据提前过滤
* 拆分任务：合并任务取ECIF粒度最新数据，拆分20个任务，每个任务的最新数据推送下游

#### 3）优化案例

1、数据倾斜：开发前，做热点Key调研

2、笛卡尔积优化：只有一条数据的配置表关联产生笛卡尔积。将配置表扩大至20行（采用lateral view explode(num_arr) tb_view As num_tb的方式炸开），num_arr是1～20的20个元素的数组。主表也新增一个JOIN列num_key，num_key是1～20的随机数。这样可以通过leftjoin的方式利用MR划分任务进行精确关联，效率：2h-->12min; map数：11470--》2140

3、任务拆分：CMSS洗数，Hive on MR 不能并行写二级分区（体会到MR和Spark的区别）

4、全量--增量：每天从增量表取32天的分区，改为初始化近32天的分区+每天进行增量更新

### 4、hive开发规范

##### 1、json加工规范

大数据量json、map等半结构化数据不允许全量加工；冗余存储会导致bad job。需上下游约定，增量供数或裁剪列等方式

##### 2、SQL 语法规范

不能ds < batch_date

不能读取所有分区

不允许超过6张表关联

禁止使用count distinct

##### 3、大IO扫描规范

单个sql扫描小于500G

单个sql扫描文件数小于5000个。因为没有优化的情况下，5000个文件就需要5000个map

##### 4、表存储规范

stored as orc tablproperties('orc.compress' = 'SNAPPY')

##### 5、多表关联需进行数据探查，避免数据倾斜