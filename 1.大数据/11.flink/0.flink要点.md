2w字玩转flink文章：https://juejin.cn/post/7127651465983688717

### 1、flink及使用场景

流批一体、实时和离线

数据源（事件、数据库）--》处理层（Yarn/K8s，提供事件驱动、时间语义、流批一体计算）--》应用层（应用、存储）

---

### 2、flink编程模型

1）分层模型

runtime层--》dataStream、Dataset API层--》Table API（Scheama信息的表结构API）--》SQL

2）flink计算模型

source端--》transformation（map、keyBy、Join）--》sink（writeAsText、addSink）

---

### 3、flink工作原理

三种角色：client、JobManager、TaskManager

执行流程：

* Flink解析**StreamGraph**。Client生成任务图**JobGraph**，提交到JobManager
* JobManager调度Job，生成**ExecutionGraph**，Job被拆分成多个任务分配到不同节点
* TaskManager部署Task，接受Job调度计划并在内部划分TaskSlot部署执行Task任务
* Task执行。JobManager、TaskManager和Client之间保持通信，回传任务状态和心跳信息，监控任务执行

---

### 4、Flink任务提交方式、部署模式。Flink On Yarn

session 模式：一个flink集群会启动到yarn上，多个作业可以连接到同一个flink集群上共享资源，共同执行

per job模式：每个提交的Job会单独启动一个新的集群到yarn上，适用于独立作业、资源隔离

---

### 5、Flink执行图

4种：StreamGraph`-> `JobGraph`-> `ExecutionGraph`->`物理执行图

1）StreamGraph：我们编写的流，通过Stream API生成

2）JobGraph：StreamGraph在client中经过算子chain链合并等优化，转换成JobGraph拓扑图

3）ExecutionGraph：JobManager将JobGraph进一步转换为ExecutionGraph，ExecutionGraph根据算子配置的并行度转变为并行化的拓扑结构

4）物理执行图：偏物理执行的概念，即jobManager负责Job调度，TaskManager最终部署Task的拓扑图结构

---

### 6、flink窗口机制

根据固定时间或长度把数据流切分到不同的窗口，提供相应的窗口window算子，进行聚合运算。有三种

1）滚动窗口(Tumbling Window)：窗口不重叠、每个窗口是独立的

~~~
// 创建数据流
        DataStream<String> stream = env.fromElements("event1", "event2", "event3", "event4", "event5");

        // 使用滚动窗口，每 10 秒处理一次数据
        stream
            .map(event -> 1)  // 每个事件映射为 1，表示一个事件
            .windowAll(TumblingProcessingTimeWindows.of(Time.seconds(10)))  // 创建 10 秒的滚动窗口
            .sum(0)  // 对窗口内的事件数量进行求和
            .print();  // 打印结果
~~~

2）滑动窗口(Sliding Window)：窗口之间有重叠，每次滑动时会有部分数据重复进入新的窗口

~~~
// 创建数据流
        DataStream<String> stream = env.fromElements("event1", "event2", "event3", "event4", "event5");

        // 使用滑动窗口，每 10 秒触发一次，每次计算过去 30 秒内的事件数量
        stream
            .map(event -> 1)  // 每个事件映射为 1，表示一个事件
            .windowAll(SlidingProcessingTimeWindows.of(Time.seconds(30), Time.seconds(10)))  // 30 秒的滑动窗口，每 10 秒触发一次
            .sum(0)  // 对每个窗口内的第1列进行求和
            .print();  // 打印结果
~~~

3）会话窗口(Session Window)：会话窗口的大小是不固定的，它基于事件到达的时间差动态变化

~~~
// 案例：基于用户行为的会话分析，每当用户的事件间隔超过 10 秒时，视为新的会话
// 创建数据流，模拟事件时间和用户 ID
        DataStream<Tuple2<String, Long>> stream = env.fromElements(
            Tuple2.of("user1", 1L),
            Tuple2.of("user2", 2L),
            Tuple2.of("user1", 5L),
            Tuple2.of("user1", 12L),
            Tuple2.of("user2", 15L)
        );
// 使用会话窗口，根据用户 ID 和事件间隔大于 10 秒来切分会话
        stream
            .keyBy(0)  // 按用户 ID 分组
            .window(EventTimeSessionWindows.withGap(Time.seconds(10)))  // 会话窗口，间隔时间为 10 秒
            .sum(1)  // 对每个窗口内的事件数量进行求和
            .print(); 
~~~

---

### 7、时间语义、watermark水印

水印是处理延迟数据的优化机制。一般数据按照顺序进入系统，但是存在网络等外部因素导致数据乱序或者延迟到达。

**水印生成**：Flink 为每个事件分配一个水印，表示当前事件时间的进展。水印通过水印生成器（`WatermarkStrategy`）来生成。

**水印触发**：当水印的时间超过窗口的结束时间时，窗口会触发计算，进行数据处理和输出。

**Flink 通过 水印（Watermarks） 机制处理乱序事件**。即使事件到达的顺序与其发生的顺序不一致，Flink 仍能根据事件的实际时间戳正确计算窗口。

1）处理时间（processing time）：事件被处理时的系统时间

~~~
stream
    .assignTimestampsAndWatermarks(WatermarkStrategy.noWatermarks())  // 处理时间下不使用 Watermark
    .window(TumblingProcessingTimeWindows.of(Time.seconds(10)))  // 按照处理时间创建滚动窗口
    .sum(1)
    .print();
~~~

2）事件时间（event time）：事件本身携带的时间戳

~~~
stream
    .assignTimestampsAndWatermarks(
        WatermarkStrategy
            .forBoundedOutOfOrderness(Time.seconds(5))  // 允许乱序时间为 5 秒
            .withTimestampAssigner((event, timestamp) -> event.getTimestamp())  // 使用事件时间戳
    )
    .keyBy(0)
    .window(TumblingEventTimeWindows.of(Time.seconds(10)))  // 按事件时间创建窗口
    .sum(1)
    .print();
~~~

在这个例子中，Flink 会根据每个事件的时间戳来创建事件时间窗口，并且处理最大延迟为 5 秒的乱序事件。

3）摄取时间（ingestion time）：事件进入flink流处理系统的事件

~~~
stream
    .assignTimestampsAndWatermarks(WatermarkStrategy.noWatermarks())  // 不使用水印
    .window(TumblingIngestionTimeWindows.of(Time.seconds(10)))  // 按摄取时间创建窗口
    .sum(1)
    .print();
~~~

##### 时间语义的选择

- **处理时间（Processing Time）**：如果要求低延迟响应，不关心事件的实际发生时间，可以选择处理时间。它简单、快速，但不适用于乱序数据和基于事件顺序的计算。
- **事件时间（Event Time）**：如果需要基于事件的真实时间戳进行精确的窗口计算，尤其是当数据流存在乱序时，事件时间是最佳选择。它**支持水印机制**，可以处理事件乱序问题，适用于大多数事件驱动的流处理场景。
- **摄取时间（Ingestion Time）**：适合快速处理不依赖事件顺序的流数据，不需要处理乱序数据时使用。它相较事件时间简单，但缺乏处理乱序事件的能力。

---

### 8、flink分布式快照

分布式快照是 Flink 提供的一种机制，它支持 **分布式一致性检查点（Checkpointing）** 和 **保存点（Savepoints）**，并确保在作业发生故障后，可以从上一个一致性快照恢复，避免数据丢失。

##### 确保一致性的几个重要概念

1. **精确一次语义（Exactly Once Semantics）**：Flink 可以保证在发生故障时，作业从最后一次成功的检查点恢复时 **不会丢失数据，也不会重复处理数据**。
2. **至少一次语义（At Least Once Semantics）**：即使在发生故障时，Flink 也会保证所有数据被处理，可能会有重复处理的情况，但数据不会丢失。
3. **存储与恢复**：Flink 的快照机制可以通过外部持久化存储（如 HDFS、S3、文件系统）来保存状态，这样即使在作业重新启动时，作业的状态依然可以恢复。

---

### 9、flink状态机制

Flink重要的特性就是其支持有状态计算。什么是有状态计算呢？即将中间的计算结果进行保存，便于后面的数据回溯和计算。当存在一个计算历史数据累计的需求时显得捉襟见肘，因此需要有方法能够保持前面的数据状态。

**1）Operator State**

**算子状态**的作用范围限定为算子任务，同一并行任务的所有数据都可以访问到相同的状态。状态对于同一任务而言是共享的。

需手动管理，适用于无 key 场景如 Source 或广播。

**2）Keyed State**

顾名思义，此类型的State状态保存形式为K-V键值对，通过K值管理和维护状态数据。

Flink对每个key维护自身状态，相同Key的数据划分到同一任务中，由Key管理其对应的状态。

自动管理，适用于分组处理。

3）状态生命周期管理

长期保存状态可能导致内存或磁盘膨胀，因此 Flink 支持：

1. **TTL（Time-To-Live）机制**：

   ```
   java
   
   
   复制编辑
   StateTtlConfig ttlConfig = StateTtlConfig
       .newBuilder(Time.hours(1))
       .setUpdateType(UpdateType.OnCreateAndWrite)
       .build();
   descriptor.enableTimeToLive(ttlConfig);
   ```

2. **窗口自动清理**：基于窗口结束时间自动销毁窗口状态。

3. **保存点状态裁剪（Savepoint Trimming）**：在保存点时清理无效状态。



注：

尽管 Flink 提供了强大的 **状态管理机制**，并且支持状态持久化（如 RocksDB 后端），但做数仓会存在 **状态爆炸** ，主要源于以下原因：

- 状态持续增长，特别是没有合适清理机制时。
- 多表关联和长时间保存历史数据会导致状态膨胀。
- RocksDB 的存储会引入性能瓶颈（尤其是磁盘 I/O）。
- 高并发时，资源消耗急剧增加，导致性能下降。

---

### 10、flink的内存管理

Flink 的内存是“进程级别的内存”（系统内存），其中一部分划给 JVM Heap，剩下的用作 Off-heap（native）缓冲、状态存储等。

1. **总进程预算**
   - `taskmanager.memory.process.size`：给出 TM 进程可用内存总量（例如 8 GB）。
2. **三大模块划分**
    Flink 1.10+ 统一内存模型下，按比例自动分配：
   - **Framework 内存**（RPC、检查点协调、状态后端元数据等）
     - 配置：`taskmanager.memory.framework-fraction`（默认 0.1，即 10%）
   - **Task 内存**（算子运行时）
     - 包括用户 Heap/Off-heap、Managed Memory。
     - 配置：
       - `taskmanager.memory.task.heap-fraction`（Heap+Managed 合计比例，默认 0.6）
       - `taskmanager.memory.task.off-heap`（如果需要额外 off-heap，用剩余比例）
   - **Network Buffer**（shuffle/流控缓冲）
     - 配置：`taskmanager.memory.network.fraction`（默认 0.2，即 20%）
3. **Managed Memory（托管内存）**
   - 从 Task 内存里再按需划分给：
     - 状态后端（RocksDB 或 heap 后端）
     - 外溢算子（排序、哈希、Window 合并）
   - 你只需调 `fraction` 或直接定 `taskmanager.memory.managed.size`，Flink 自动管理回收。
4. **网络缓冲区**
   - 流式：Credit-based，可重用
   - 批式（Shuffle）：预分配固定 buffers
   - 大小由 `network.fraction` 控制，或老版里单独设 `network.memory.min/max`、`buffer.size`。
5. **堆上 vs 堆外**
   - **堆上 (Heap)**：算子新对象、Java GC 管理
   - **堆外 (Off-heap)**：减少 GC 停顿，用 Netty 直接内存；Framework + Managed Memory 都可配置为 off-heap。

------

**精简示例**

```yaml
taskmanager.memory.process.size: 8g
taskmanager.memory.framework-fraction: 0.1
taskmanager.memory.task.heap-fraction: 0.6
taskmanager.memory.network.fraction: 0.2
# 这 8 GB 就是 OS 层面给整个 JVM 进程的内存预算，里面分出了：
# Off-heap 托管／框架（8 GB×0.1 = 0.8 GB）
# task Heap（8 GB×0.6 = 4.8 GB）
# Off-heap 网络缓冲（8 GB×0.2 = 1.6 GB）
# 剩余 10% 可作为 off-heap 托管或用户算子使用
```

只要记住“三大用途 + 托管，还有堆外内存”三步走，面试问起如何分配就能一气呵成。

---

### 11、Flink和Spark Streaming有什么区别

1、数据处理方式：Flink是原生流处理；spark Streaming本质是微批处理，每个批次有固定时间间隔。延迟通常是秒级

2、状态管理：Spark straming依赖外部存储，如redis来管理状态

3、时间语义：Spark Streaming主要是处理时间，事件时间支持弱，所以不支持乱序数据

4、窗口机制：Spark Streaming支持滚动和滑动窗口，灵活性有限

5、容错机制：WAL + RDD lineage，延迟恢复，近似 Exactly Once

---

# 二、进阶

### 12、flink背压？怎么解决？

1、通俗理解：就像水管堵了，下游排水太慢，上游得减速，甚至停下来

表现：

* 延迟上升（指标监控 busy time = 100%）
* checkpoint卡住或者很慢
* 吞吐量下降
* kafka等Source数据挤压
* Dashboard出现红色的节点

2、flink自身应对：采用链式算子阻塞传播+信号反馈的方式自动处理背压

1）反压传播机制：逐级向源头减速、避免内存溢出

2）基于异步网络通信的流控机制

3）反压监控

3、实战如何解决

1）算子优化

2）Sink优化（尽量使用异步Sink，增加Sink并行度、优化批量写入、缓冲区大小

3）资源扩展（增加并行度set parallelism(n)、调大TaskManager的slot数量）

4）避免数据倾斜（使用更合适的keyBy方式，增加随机因子避免热点key）

5）状态优化（压缩窗口时间、清理状态TTL）

6）调整缓冲区（增加网络buffer大小。如：taskmanager.network.memory.fraction=0.2）

7）GC优化（合理设置JVM参数，减少Full GC：`-XX:+UseG1GC`，加大堆内存）

4、实际排查步骤

1）观察WebUI的backpressure页面，确定背压在哪个节点

2）启用taskmanager.log.level=debug检查是否有GC、OOM、阻塞写日志

3）结合指标监控（如prometheus + Grafana）查看CPU、内存网络是否打满

4）检查逻辑，是否使用外部服务、有无数据倾斜

### 13、flink的双流Join

与批处理 Join 不同，流处理中的 Join 要考虑**数据是连续不断到达的，且可能乱序、延迟**的问题。

1、最常用的：interval join

两个流基于某个key，在一定时间范围内进行Join。使用该方法的业务需求需要满足以下条件：

1）支持设置Join 的时间范围（如前 10 分钟、后 5 分钟）

2）两个数据流都必须是keyedStream

3）两个流都必须基于Event Time（都支持乱序、迟到）

2、Window Join

将两个流放入同一个时间窗口进行 Join

特点：

1）基于processing time或者event time

2）数据必须满足对其时间窗口

**说明**：Flink SQL 支持事件时间 Join，背后也是基于 Interval Join 实现。