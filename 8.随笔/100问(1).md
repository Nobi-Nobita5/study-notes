1. HDFS的架构

   1. https://blog.csdn.net/solihawk/article/details/123981573
      1.1解释下FsImage和Edits的作用，他们是怎么工作的？

     > Hadoop Distributed File System（HDFS）是一种分布式文件系统，用于存储大量数据并在集群上进行分布式处理。FsImage和Edits是HDFS的两个重要组件，它们都是元数据存储的核心。
     >
     > 1. FsImage：FsImage（文件系统映像）是HDFS NameNode的持久化元数据存储。FsImage包含了HDFS集群中所有文件和目录的信息，例如权限、所有者、副本数等。FsImage文件是一个序列化的镜像，包含了NameNode内存中文件系统的全局快照。FsImage在NameNode启动时加载到内存，以便在运行时迅速响应客户端请求。
     >
     > 2. Edits：Edits（编辑日志）是HDFS中用于记录文件系统更改的日志文件。NameNode在内存中维护文件系统的状态，当客户端对文件系统进行操作（如创建、删除或重命名文件/目录）时，NameNode会将这些操作记录到Edits日志中。Edits日志是增量式的，只记录自上次FsImage创建以来发生的更改。
     >
     > FsImage和Edits的工作原理：
     >
     > 1. 当NameNode启动时，它首先从FsImage文件加载文件系统元数据到内存。
     > 2. 随后，NameNode会从Edits日志中回放所有记录的更改，以便将内存中的文件系统状态更新到最新。
     > 3. 在NameNode运行期间，所有对文件系统的更改都会记录在Edits日志中。
     > 4. 为了防止Edits日志过大，NameNode会定期执行一次检查点操作（checkpoint），这个过程包括将FsImage和Edits日志合并，并创建一个新的FsImage文件。新的FsImage包含了所有最近的文件系统更改，而Edits日志会被清空或截断，从而避免了Edits日志无限制增长。
     >
     > 总的来说，FsImage和Edits在HDFS中扮演着至关重要的角色，它们一起维护了HDFS文件系统的元数据，并确保了NameNode在故障恢复后能够正确恢复文件系统状态。

2. HDFS的读写流程	

3. Secondary NameNode 了解吗，它的工作机制是怎样的	

4. join原理	

5. yarn 的任务提交流程是怎样的	

6. zookeeper集群的节点数为什么建议奇数台	

7. Zab协议	

8. 简述kafka的架构	

9. kafka是如何保证数据不丢失和数据不重复	

10. kafka中的数据是有序的吗，如何保证有序的呢	

11. kafka的数据是放在磁盘上还是内存上，为什么速度会快	

12. HBase 中 compact 用途是什么，什么时候触发，分为哪两种，有什么区别	

13. 说一下HBase 的 rowkey 设计原则	

14. hive的join底层实现	

15. Order By和Sort By的区别	

16. 自定义过UDF、UDTF函数吗	

17. Hive优化	

18. 简述hadoop 和 spark 的不同点（为什么spark更快）	

19. 你知道Application、Job、Stage、Task他们之间的关系吗		

20. 宽依赖和窄依赖之间的区别	

21. sparksql的三种join实现		

22. 简述SparkStreaming窗口函数的原理	

23. 简单介绍一下Flink	

24. Flink和SparkStreaming区别		

    > Apache Flink 和 Apache Spark 都是大数据处理框架，但在流式处理方面存在一些显著差异：
    >
    > 1. **本质上的流式处理 vs 微批处理**:
    >    - Flink 是一个本质上的流式处理系统，它可以在流上进行事件级的实时处理。
    >    - Spark 最初是为批处理设计的，后来引入了 Spark Streaming，采用微批处理方式进行流式处理。在 Spark Structured Streaming 中，虽然微批处理的概念对用户更加透明，但底层仍然是基于微批处理。
    >
    > 2. **事件时间 vs 处理时间**:
    >    - Flink 支持基于事件时间 (event time) 和处理时间 (processing time) 的处理，并且提供了强大的事件时间处理能力，这对于处理有延迟的数据或乱序事件很有用。
    >    - Spark 在其 Structured Streaming 中也引入了事件时间的支持，但 Flink 在事件时间处理上通常被认为更加成熟和健壮。
    >
    > 3. **状态管理**:
    >    - Flink 提供了强大的状态管理能力，**允许用户以分布式的方式存储和管理大量的状态信息，并且支持精细化的状态恢复**。
    >    - Spark 的状态管理相对简单，并且在恢复状态时，通常**需要从最近的检查点或写入的日志开始重新处理数据**。
    >
    > 4. **窗口操作**:
    >    - Flink 提供了丰富的窗口操作，如滚动窗口、滑动窗口、会话窗口，以及对事件时间和处理时间的支持。
    >    - Spark 也支持窗口操作，但相对而言，Flink 在窗口操作方面更加灵活和强大。
    >
    > 5. **容错和恢复**:
    >    - Flink 提供了**分布式快照的机制来保证状态的一致性，并允许在故障发生时进行快速恢复**。
    >    - Spark 通过检查点和写前日志（write-ahead logs）来保证容错，但在大规模状态管理和快速恢复方面，Flink 通常具有优势。
    >
    > 6. **社区和生态系统**:
    >    - Spark 有一个庞大的社区和丰富的生态系统，提供了包括机器学习、图计算等在内的多个库。
    >    - Flink 的社区相对较小，但在流式处理方面非常活跃，并且专注于提供高性能的流式处理能力。
    >
    > 综上所述，选择 Flink 还是 Spark 取决于具体的用例和需求。Flink 在纯流式处理、事件时间处理和状态管理方面具有优势，而 Spark 则具有更大的社区支持和更丰富的生态系统。

25. java中==和equals的区别	

26. HashMap底层实现	

27. HashMap扩容过程	

28. 异常体系	

29. JVM一个类的加载过程	

30. JVM中的垃圾回收算法	

31. JVM垃圾收集器 	

32. java实现多线程有几种方式	

33. 线程池相关内容	

34. synchronized 的原理	

35. TCP连接管理	

36. TCP和UDP的区别	

37. 浏览器输入URL到显示页面的过程	

38. 进程和线程的区别	

39. 什么是死锁以及死锁的四个条件	

40. 简述事务	

41. 数据库事务并发会引发哪些问题	

42. MVCC讲一下（怎么实现）	

44. 数据仓库建模的方法有哪些	

    https://blog.csdn.net/qq_26442553/article/details/105506364

45. 事实表的设计过程	

46. 留存问题	

47. 数据倾斜	


-------------------------
--携程
1. HDFS的写入流程？如果一台机器宕机，HDFS怎么保证数据的一致性？如果只存活一台机器又会发生什么情况？

3. 如果数据量比较大，如何解决NameNode 的内存瓶颈？

4. MapReduce Shuffle中Reduce是怎么获得Map输出的分区文件，Map主动推还是Reduce主动拉？

   > 在 MapReduce 模型中，Map 阶段的输出在 Reduce 阶段前需要经历 Shuffle 和 Sort 过程。这个过程涉及到数据在 Map 端和 Reduce 端之间的移动。
   >
   > 在 Shuffle 过程中，是 Reduce 任务主动拉取 Map 任务输出的数据。
   >
   > 具体过程如下：
   >
   > 1. Map 任务执行完毕后，会将结果按照 Reduce 任务的数量分区，并将各个分区的数据写到本地磁盘。
   > 2. 每个 Reduce 任务会从 JobTracker（或 YARN 中的 ApplicationMaster）获取它需要处理的 Map 任务列表。
   > 3. Reduce 任务根据得到的 Map 任务列表，对每一个 Map 任务，通过 HTTP 方式从 Map 任务所在节点的本地磁盘拉取对应的分区数据。
   > 4. Reduce 任务获取到数据后，会对数据进行排序（Sort）并执行 Reduce 操作。
   >
   > 这样设计的原因是，一般来说 Map 任务的数量比 Reduce 任务的数量要多得多，如果使用 Map 任务主动推的方式，会造成 Reduce 任务端的网络接口和 IO 成为瓶颈。反之，如果使用 Reduce 任务主动拉取的方式，可以更好地利用网络带宽，避免在 Reduce 任务端形成网络和 IO 瓶颈。

5. Kafka如何实现顺序消费？

6. Spark Streaming消费Kafka的两种方式比较。如何提高Spark Streaming消费Kafka的并行度？

7. 如何保证Spark Streaming的精准一次性消费？

8. 项目中Spark Streaming消费Kakfa的offset保存在哪里？为什么不采用checkpoint保存offset，有什么缺点？

9. 对Spark RDD的理解。

10. Spark作业运行流程？（从standalone和yarn两种模式进行阐述）

11. 项目中Spark采用的那种模式搭建的？为什么采用standalone而不采用yarn模式？

12. 为什么Spark Shuffle比MapReduce Shuffle快（至少说出4个理由）？

13. Spark3新特性

14. Java中保证线程安全的方法有哪些？

15. 一个volatile修饰的变量，如果两个线程同时去写这个变量，线程安全吗？如果不安全该怎么使他变得安全？

16. Linux中怎么查看一个进程打开了哪些文件？

17. 算法题：二叉树非递归中序遍历

------------------------------
