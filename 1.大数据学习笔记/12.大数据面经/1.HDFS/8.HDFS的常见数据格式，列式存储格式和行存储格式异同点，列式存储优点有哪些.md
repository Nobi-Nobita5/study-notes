#### 一、HDFS的常见数据格式

> 常用的文件格式有：TextFile、SequenceFile、Avro、Parquet、RC & ORC

##### 1.TextFile

> 常采用csv、json等固定长度的纯文本格式

**优点：**

* 便于与其他应用程序、脚本进行数据交换
* 易读性好、便于理解

**缺点：**

* 数据存储量非常庞大
* 查询效率不高
* 不支持块压缩

##### 2.SequenceFile

> 按行存储二进制键值对数据，HDFS自带

**特点：**

* 常用于mapreduce作业之间传输数据
* 二进制文件直接将<key,value>序列化到文件中
* 可用于Hadoop中小文件的打包存档
* 支持记录压缩、块压缩
* 二进制文件、可读性低

##### 3.Avro

> Apache Avro是一个序列化系统，出自[Hadoop](https://so.csdn.net/so/search?q=Hadoop&spm=1001.2101.3001.7020)之父Doug Cutting

**特点：**

- **以json格式存储数据定义（对表的描述、字段、字段类型等），以二进制格式存储数据**
- 比较通用的数据格式
- 具有丰富的数据结构
- 快速可压缩的二进制数据格式
- 自带远程调用RPC
- 可读性低

**基本操作**

1. 生成avro文件

~~~json
//1.制作schema信息文件（user.avsc）
{
"namespace": "example.avro",
 "type": "record",
 "name": "User",
 "fields": [
     {"name": "name", "type": "string"},
     {"name": "favorite_number",  "type": ["int", "null"]},
     {"name": "favorite_color", "type": ["string", "null"]}
]}

//2.制作json文件(user.json)
{"name": "Alyssa", "favorite_number":{"int": 256}, "favorite_color": null}
{"name": "Ben", "favorite_number": {"int": 7}, "favorite_color": {"string":"red"}}
{"name": "Charlie", "favorite_number": null, "favorite_color": {"string":"blue"}


//3.制作文件（使用avro-tools-1.8.2.jar），利用user.avsc、user.json，制作文件user.avro
java -jar avro-tools-1.8.2.jar fromjson --schema-file user.avsc user.json > user.avro

~~~

2. 读取avro文件元数据、数据

~~~json
//获取元数据
java -jar avro-tools-1.8.2.jar getmeta user.avro

//获取数据
java -jar avro-tools-1.8.2.jar tojson user.avro
~~~

##### 4.Parquet

> Apache Parquet是Hadoop生态系统中任何项目都能使用的列式存储格式，由Twitter和Cloudera合作开发

- Parquet格式是Spark SQL默认的数据源
- 按列进行存储，按需读取列，压缩编码可以降低磁盘存储空间（比如有5个"d"，它能够将数据转化成类似于这种结构：“d5”）

##### 5.RC

> 由Facebook开源

- 存储行集合，并在集合中以列格式存储行数据
- 引入轻量级索引，允许跳过不相关的行块
- 可分割，允许并行处理行集合
- 支持块压缩

##### 6.ORC
> RC的优化版本

**特点**

- 常用于Hive
- 压缩率极高

**在Hive中常用的使用方式：一般读入源文件为Avro格式，在Hive中的中间过程可以使用ORC存储，而最后保存也选择Avro格式保存。因为Avro格式比较通用，而ORC格式在很多地方并不能使用。**



>  各种格式比较

![](F:\学习资料\学习笔记Typora\1.大数据学习笔记\图片资源\HDFS存储格式比较.png)

***可分割：**文件从某个位置切分开来，是否仍旧能够读取数据*

***模式演化（元数据）：**更改schema，生产者和消费者可以同时使用schema的不同版本，且一切都可以继续工作*



> 存储格式的选择

读取（速度从高到低排序）

* Avro：查询随时间变化，支持扩展字段
* Parquet：适合在宽表上查询少数列
* Parquet & ORC：以牺牲性能为代价，优化读取能力
* TextFile：可读性最佳，但是文件读取速度慢

**Hive查询**（速度从高到低排序）

* ORC**（常用）**：几乎专门为Hive定制的格式，速度很快
* Parquet**（常用）**
* Text
* Avro**（常用）**：占地小，节省磁盘空间，也是比较通用的格式
* SequenceFile：占地小，节省磁盘空间；本身是为了MR的k、v对设计，而非Hive，所以对于Hive来说速度最慢。



#### 二、列式存储格式和行存储格式异同点，列式存储优点有哪些?

##### 1.写入：

 行存储的写入是一次完成，**数据的完整性**因此可以确定。

 列存储需要把一行记录拆分成单列保存，写入次数明显比行存储多。

 行存储在写入上占有很大的优势

 


##### 2.数据修改：

 行存储是在指定位置写入一次，列存储是将磁盘定位到多个列上分别写入。

 行存储在数据修改也是占优的

 


##### 3.数据读取：

 行存储通常将一行数据完全读出，如果只需要其中几列数据，就会存在冗余列

 列存储每次读取的数据是集合中的一段或者全部。

 由于列储存的数据是同质的，这种情况使数据解析变得容易。行存储则复杂的多，因为在一行记录中保存了多种类型的数据，数据解析需要在多种数据类型之间频繁转换，这个操作很消耗cpu

 所以列存储的解析过程中更有利于分析大数据

##### 4.总结：

显而易见，两种存储格式都有各自的优缺点：行存储的写入是一次性完成，消耗的时间比列存储少，并且能够保证数据的完整性，缺点是数据读取过程中会产生冗余数据，如果只有少量数据，此影响可以忽略；数量大可能会影响到数据的处理效率。列存储在写入效率、保证数据完整性上都不如行存储，它的优势是在读取过程，不会产生冗余数据，这对数据完整性要求不高的大数据处理领域，比如互联网，犹为重要。



> 列存储物理结构

![](F:\学习资料\学习笔记Typora\1.大数据学习笔记\图片资源\HBASE物理存储结构.png)

> 列式存储(Column-based)是相对于传统[关系型数据库](https://so.csdn.net/so/search?q=关系型数据库&spm=1001.2101.3001.7020)的行式存储(Row-based)来说的。简单来说两者的区别就是如何组织表。
>
> 将表放入存储系统中有两种方法，而我们绝大部分是采用行存储的。行存储法是将各行放入连续的物理位置，这很像传统的记录和文件系统。列存储法是将数据按照列存储到数据库中，与行存储类似，下图是两种存储方法的图形化解释。

![](F:\学习资料\学习笔记Typora\1.大数据学习笔记\图片资源\列存储与行存储.png)

* 由 Row-based store 可知行存储的多行数据写入是一次完成的，列存储由于需要把传统的行记录拆分成多列保存，然后一列一列写入，**写入次数明显比行存储多（意味着磁头调度次数多，而磁头调度是需要时间的，一般在1ms~10ms)**，再加上磁头需要在盘片上移动和定位花费的时间，实际时间消耗会更大。

  **列存储在读取数据的时候，可以选择只读取需要信息的列；行存储需要读取所有数据，耗费时间长且会存在冗余列。**

  就算行存储建立索引之后，查询的也是该行的所有列；

  而列存储方式通过**行键RowKey和列名**可以快速查询到指定列的数据。