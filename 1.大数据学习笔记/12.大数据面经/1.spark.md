[最全Spark保姆级面试教程 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/440179932)

1. **介绍下Spark**

2. **谈一谈Spark的生态体系**

3.  **Spark的任务执行流程**  

   ![](F:\学习资料\学习笔记Typora\1.大数据学习笔记\图片资源\Spark任务执行流程.png)

   可以结合运行模式及原理细说

   * 客户端提交任务，创建Driver进程并初始化SparkContext，SparkContext对象代表了和一个集群的连接
   * SparkContext向Cluster Manager（资源管理器）申请资源
   * Cluster Manager 选择合适的worker节点（一个或多个）创建executor进程
   * executor向driver端注册，并等待其分配任务
   * SparkContext根据RDDs之间的依赖关系构建DAG图（有向无环图），DAGScheduler将DAG图解析成Stage，每个Stage有多个task，形成taskset发送给task Scheduler，由task Scheduler将Task发送给Executor运行
   * Executor启动Task线程执行具体任务，运行完释放所有资源

4. **Yarn Cluster和Yarn Client模式的区别**

   * 在Yarn模式中，Spark应用程序有两种运行模式：
     		**yarn-client**：Driver程序运行在**本地客户端**，适用于交互、调试，希望立即看到app的输出。因资源调度、任务分发会和yarn集群产生大量网络通信，不建议生产上使用。
       		**yarn-cluster**：Driver程序运行在由RM启动的 AppMaster中，适用于生产环境
     二者的主要区别：Driver在哪里。

   * Yarn Cluster模式

     ![img](https://pic4.zhimg.com/80/v2-b9239e2e387f9ba7d3b4d2c30b14f307_1440w.jpg)

   * ![img](https://pic2.zhimg.com/80/v2-36da1a71b1d1c36cde73465504c2f2a5_1440w.jpg)